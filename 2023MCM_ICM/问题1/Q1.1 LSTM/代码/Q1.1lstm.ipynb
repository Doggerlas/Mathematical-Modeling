{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://blog.csdn.net/Q_M_X_D_D_/article/details/109366895"
      ],
      "metadata": {
        "id": "dPfW0zMHs-uN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8CDd208TWJ6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 导入数据"
      ],
      "metadata": {
        "id": "fO2Ir3cLhvVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_excel(\"cpss_v2.xlsx\")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pLzStpuLUOUe",
        "outputId": "6baeb918-9462-4471-b670-53278d1efd12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date   cn     wd       a     b  1t  2t  3t  4t  5t  6t  7mt\n",
              "0   2022-01-07  202  slump   80630  1362   1   3  23  39  24   9    1\n",
              "1   2022-01-08  203  crank  101503  1763   1   5  23  31  24  14    2\n",
              "2   2022-01-09  204  gorge   91477  1913   1   3  13  27  30  22    4\n",
              "3   2022-01-10  205  query  107134  2242   1   4  16  30  30  17    2\n",
              "4   2022-01-11  206  drink  153880  3017   1   9  35  34  16   5    1\n",
              "..         ...  ...    ...     ...   ...  ..  ..  ..  ..  ..  ..  ...\n",
              "354 2022-12-27  556  condo   20879  2012   0   2  17  35  29  14    3\n",
              "355 2022-12-28  557  impel   20160  1937   0   3  21  40  25   9    1\n",
              "356 2022-12-29  558  havoc   20001  1919   0   2  16  38  30  12    2\n",
              "357 2022-12-30  559  molar   21204  1973   0   4  21  38  26   9    1\n",
              "358 2022-12-31  560  manly   20380  1899   0   2  17  37  29  12    2\n",
              "\n",
              "[359 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e83e8055-e611-41b5-ab8f-752371d232cb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>cn</th>\n",
              "      <th>wd</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>1t</th>\n",
              "      <th>2t</th>\n",
              "      <th>3t</th>\n",
              "      <th>4t</th>\n",
              "      <th>5t</th>\n",
              "      <th>6t</th>\n",
              "      <th>7mt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-01-07</td>\n",
              "      <td>202</td>\n",
              "      <td>slump</td>\n",
              "      <td>80630</td>\n",
              "      <td>1362</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>39</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-01-08</td>\n",
              "      <td>203</td>\n",
              "      <td>crank</td>\n",
              "      <td>101503</td>\n",
              "      <td>1763</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>31</td>\n",
              "      <td>24</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-01-09</td>\n",
              "      <td>204</td>\n",
              "      <td>gorge</td>\n",
              "      <td>91477</td>\n",
              "      <td>1913</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>30</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-01-10</td>\n",
              "      <td>205</td>\n",
              "      <td>query</td>\n",
              "      <td>107134</td>\n",
              "      <td>2242</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-01-11</td>\n",
              "      <td>206</td>\n",
              "      <td>drink</td>\n",
              "      <td>153880</td>\n",
              "      <td>3017</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>35</td>\n",
              "      <td>34</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>2022-12-27</td>\n",
              "      <td>556</td>\n",
              "      <td>condo</td>\n",
              "      <td>20879</td>\n",
              "      <td>2012</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>35</td>\n",
              "      <td>29</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>2022-12-28</td>\n",
              "      <td>557</td>\n",
              "      <td>impel</td>\n",
              "      <td>20160</td>\n",
              "      <td>1937</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>40</td>\n",
              "      <td>25</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>2022-12-29</td>\n",
              "      <td>558</td>\n",
              "      <td>havoc</td>\n",
              "      <td>20001</td>\n",
              "      <td>1919</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>38</td>\n",
              "      <td>30</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>559</td>\n",
              "      <td>molar</td>\n",
              "      <td>21204</td>\n",
              "      <td>1973</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>38</td>\n",
              "      <td>26</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>560</td>\n",
              "      <td>manly</td>\n",
              "      <td>20380</td>\n",
              "      <td>1899</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>37</td>\n",
              "      <td>29</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>359 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e83e8055-e611-41b5-ab8f-752371d232cb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e83e8055-e611-41b5-ab8f-752371d232cb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e83e8055-e611-41b5-ab8f-752371d232cb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data[['Date','a']]\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YDr5W7ChVtvq",
        "outputId": "1d63dabe-f322-45b1-d7be-74f2edd80abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       a\n",
              "0   2022-01-07   80630\n",
              "1   2022-01-08  101503\n",
              "2   2022-01-09   91477\n",
              "3   2022-01-10  107134\n",
              "4   2022-01-11  153880\n",
              "..         ...     ...\n",
              "354 2022-12-27   20879\n",
              "355 2022-12-28   20160\n",
              "356 2022-12-29   20001\n",
              "357 2022-12-30   21204\n",
              "358 2022-12-31   20380\n",
              "\n",
              "[359 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e801ad3-159c-41ad-8fd6-95ec42870034\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-01-07</td>\n",
              "      <td>80630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-01-08</td>\n",
              "      <td>101503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-01-09</td>\n",
              "      <td>91477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-01-10</td>\n",
              "      <td>107134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-01-11</td>\n",
              "      <td>153880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>2022-12-27</td>\n",
              "      <td>20879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>2022-12-28</td>\n",
              "      <td>20160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>2022-12-29</td>\n",
              "      <td>20001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>21204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>20380</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>359 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e801ad3-159c-41ad-8fd6-95ec42870034')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e801ad3-159c-41ad-8fd6-95ec42870034 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e801ad3-159c-41ad-8fd6-95ec42870034');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 时间与Number of reported results折线图\n",
        "series = data.set_index(['Date'], drop=True)# 原始数据\n",
        "plt.figure(figsize=(10, 6))\n",
        " \n",
        "series['a'].plot()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "kvbfY3nzhC4P",
        "outputId": "b6815fd8-e60c-40b1-ab2c-3a02076623da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 构建数据集"
      ],
      "metadata": {
        "id": "o3r-_JQohm9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame格式转换为二维数组，再进行数据差分\n",
        "def difference(data_set,interval=1):\n",
        "    diff=list()\n",
        "    for i in range(interval,len(data_set)):\n",
        "        value=data_set[i]-data_set[i-interval]\n",
        "        diff.append(value)\n",
        "    return pd.Series(diff)\n",
        " \n",
        "# 这里的series是之前数据预处理后得到的DateFrame型数据\n",
        "raw_value=series.values\n",
        "diff_value=difference(raw_value,1)\n",
        "diff_value # 差分值"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOQBKO2fhg-y",
        "outputId": "3f75b9db-94cb-4ed0-9333-2d15849af014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [20873]\n",
              "1      [-10026]\n",
              "2       [15657]\n",
              "3       [46746]\n",
              "4      [-16294]\n",
              "         ...   \n",
              "353       [868]\n",
              "354      [-719]\n",
              "355      [-159]\n",
              "356      [1203]\n",
              "357      [-824]\n",
              "Length: 358, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 时间序列转化为监督学习集：两两一组 前一个差分是输入 后一个差分是输出\n",
        "def timeseries_to_supervised(data,lag=1):\n",
        "    df=pd.DataFrame(data)\n",
        "    columns=[df.shift(1)]\n",
        "    columns.append(df)\n",
        "    df=pd.concat(columns,axis=1)\n",
        "    df.fillna(0,inplace=True)\n",
        "    return df\n",
        " \n",
        "supervised=timeseries_to_supervised(diff_value,1)\n",
        "supervised_value=supervised.values\n",
        "supervised_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWmleY20jCP0",
        "outputId": "f6ab06db-9dd1-41d2-cd6c-830369857ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, array([20873])],\n",
              "       [array([20873]), array([-10026])],\n",
              "       [array([-10026]), array([15657])],\n",
              "       [array([15657]), array([46746])],\n",
              "       [array([46746]), array([-16294])],\n",
              "       [array([-16294]), array([-4860])],\n",
              "       [array([-4860]), array([36758])],\n",
              "       [array([36758]), array([36396])],\n",
              "       [array([36396]), array([3729])],\n",
              "       [array([3729]), array([12588])],\n",
              "       [array([12588]), array([-1247])],\n",
              "       [array([-1247]), array([59672])],\n",
              "       [array([59672]), array([-36658])],\n",
              "       [array([-36658]), array([29763])],\n",
              "       [array([29763]), array([-32238])],\n",
              "       [array([-32238]), array([28440])],\n",
              "       [array([28440]), array([-11891])],\n",
              "       [array([-11891]), array([18366])],\n",
              "       [array([18366]), array([25944])],\n",
              "       [array([25944]), array([29496])],\n",
              "       [array([29496]), array([-34876])],\n",
              "       [array([-34876]), array([16252])],\n",
              "       [array([16252]), array([-18533])],\n",
              "       [array([-18533]), array([46627])],\n",
              "       [array([46627]), array([10349])],\n",
              "       [array([10349]), array([10245])],\n",
              "       [array([10245]), array([-3732])],\n",
              "       [array([-3732]), array([1503])],\n",
              "       [array([1503]), array([-39981])],\n",
              "       [array([-39981]), array([-8680])],\n",
              "       [array([-8680]), array([-22790])],\n",
              "       [array([-22790]), array([48008])],\n",
              "       [array([48008]), array([-30864])],\n",
              "       [array([-30864]), array([-542])],\n",
              "       [array([-542]), array([-26004])],\n",
              "       [array([-26004]), array([-8941])],\n",
              "       [array([-8941]), array([7586])],\n",
              "       [array([7586]), array([-15950])],\n",
              "       [array([-15950]), array([26315])],\n",
              "       [array([26315]), array([1885])],\n",
              "       [array([1885]), array([52282])],\n",
              "       [array([52282]), array([-76765])],\n",
              "       [array([-76765]), array([17089])],\n",
              "       [array([17089]), array([-9021])],\n",
              "       [array([-9021]), array([5425])],\n",
              "       [array([5425]), array([27625])],\n",
              "       [array([27625]), array([-28780])],\n",
              "       [array([-28780]), array([-26902])],\n",
              "       [array([-26902]), array([5233])],\n",
              "       [array([5233]), array([-7544])],\n",
              "       [array([-7544]), array([2050])],\n",
              "       [array([2050]), array([681])],\n",
              "       [array([681]), array([-10957])],\n",
              "       [array([-10957]), array([17167])],\n",
              "       [array([17167]), array([-17286])],\n",
              "       [array([-17286]), array([-36288])],\n",
              "       [array([-36288]), array([26165])],\n",
              "       [array([26165]), array([-11300])],\n",
              "       [array([-11300]), array([0])],\n",
              "       [array([0]), array([-11122])],\n",
              "       [array([-11122]), array([-5674])],\n",
              "       [array([-5674]), array([7085])],\n",
              "       [array([7085]), array([17465])],\n",
              "       [array([17465]), array([-34300])],\n",
              "       [array([-34300]), array([-12613])],\n",
              "       [array([-12613]), array([5970])],\n",
              "       [array([5970]), array([17449])],\n",
              "       [array([17449]), array([15001])],\n",
              "       [array([15001]), array([-48785])],\n",
              "       [array([-48785]), array([10759])],\n",
              "       [array([10759]), array([-23519])],\n",
              "       [array([-23519]), array([-1324])],\n",
              "       [array([-1324]), array([18649])],\n",
              "       [array([18649]), array([-13475])],\n",
              "       [array([-13475]), array([-3376])],\n",
              "       [array([-3376]), array([12281])],\n",
              "       [array([12281]), array([-18869])],\n",
              "       [array([-18869]), array([-690])],\n",
              "       [array([-690]), array([15961])],\n",
              "       [array([15961]), array([8228])],\n",
              "       [array([8228]), array([-24626])],\n",
              "       [array([-24626]), array([9069])],\n",
              "       [array([9069]), array([-22920])],\n",
              "       [array([-22920]), array([9429])],\n",
              "       [array([9429]), array([10431])],\n",
              "       [array([10431]), array([-30547])],\n",
              "       [array([-30547]), array([5119])],\n",
              "       [array([5119]), array([-8295])],\n",
              "       [array([-8295]), array([-3500])],\n",
              "       [array([-3500]), array([-95])],\n",
              "       [array([-95]), array([23397])],\n",
              "       [array([23397]), array([-6948])],\n",
              "       [array([-6948]), array([-7969])],\n",
              "       [array([-7969]), array([-16413])],\n",
              "       [array([-16413]), array([5079])],\n",
              "       [array([5079]), array([8348])],\n",
              "       [array([8348]), array([-9807])],\n",
              "       [array([-9807]), array([16543])],\n",
              "       [array([16543]), array([-22004])],\n",
              "       [array([-22004]), array([-1306])],\n",
              "       [array([-1306]), array([5702])],\n",
              "       [array([5702]), array([-3484])],\n",
              "       [array([-3484]), array([-6892])],\n",
              "       [array([-6892]), array([-4052])],\n",
              "       [array([-4052]), array([21277])],\n",
              "       [array([21277]), array([-23670])],\n",
              "       [array([-23670]), array([1890])],\n",
              "       [array([1890]), array([-5904])],\n",
              "       [array([-5904]), array([11605])],\n",
              "       [array([11605]), array([-4186])],\n",
              "       [array([-4186]), array([-9993])],\n",
              "       [array([-9993]), array([17678])],\n",
              "       [array([17678]), array([-28661])],\n",
              "       [array([-28661]), array([-333])],\n",
              "       [array([-333]), array([17985])],\n",
              "       [array([17985]), array([-9826])],\n",
              "       [array([-9826]), array([21933])],\n",
              "       [array([21933]), array([-21771])],\n",
              "       [array([-21771]), array([-9687])],\n",
              "       [array([-9687]), array([-1834])],\n",
              "       [array([-1834]), array([-1940])],\n",
              "       [array([-1940]), array([16414])],\n",
              "       [array([16414]), array([-14520])],\n",
              "       [array([-14520]), array([5034])],\n",
              "       [array([5034]), array([-3773])],\n",
              "       [array([-3773]), array([1912])],\n",
              "       [array([1912]), array([-4360])],\n",
              "       [array([-4360]), array([-6110])],\n",
              "       [array([-6110]), array([1234])],\n",
              "       [array([1234]), array([2373])],\n",
              "       [array([2373]), array([3211])],\n",
              "       [array([3211]), array([-3013])],\n",
              "       [array([-3013]), array([-1036])],\n",
              "       [array([-1036]), array([-3070])],\n",
              "       [array([-3070]), array([1095])],\n",
              "       [array([1095]), array([-1478])],\n",
              "       [array([-1478]), array([-3051])],\n",
              "       [array([-3051]), array([-657])],\n",
              "       [array([-657]), array([465])],\n",
              "       [array([465]), array([658])],\n",
              "       [array([658]), array([-3777])],\n",
              "       [array([-3777]), array([-3230])],\n",
              "       [array([-3230]), array([4130])],\n",
              "       [array([4130]), array([1799])],\n",
              "       [array([1799]), array([473])],\n",
              "       [array([473]), array([-1963])],\n",
              "       [array([-1963]), array([4153])],\n",
              "       [array([4153]), array([-7168])],\n",
              "       [array([-7168]), array([-1525])],\n",
              "       [array([-1525]), array([1740])],\n",
              "       [array([1740]), array([513])],\n",
              "       [array([513]), array([2035])],\n",
              "       [array([2035]), array([-1006])],\n",
              "       [array([-1006]), array([-4644])],\n",
              "       [array([-4644]), array([-3418])],\n",
              "       [array([-3418]), array([4726])],\n",
              "       [array([4726]), array([-2882])],\n",
              "       [array([-2882]), array([6166])],\n",
              "       [array([6166]), array([-3979])],\n",
              "       [array([-3979]), array([-2559])],\n",
              "       [array([-2559]), array([1235])],\n",
              "       [array([1235]), array([-7460])],\n",
              "       [array([-7460]), array([8154])],\n",
              "       [array([8154]), array([-4875])],\n",
              "       [array([-4875]), array([2858])],\n",
              "       [array([2858]), array([-5697])],\n",
              "       [array([-5697]), array([5466])],\n",
              "       [array([5466]), array([-2494])],\n",
              "       [array([-2494]), array([-4528])],\n",
              "       [array([-4528]), array([4361])],\n",
              "       [array([4361]), array([-2464])],\n",
              "       [array([-2464]), array([-674])],\n",
              "       [array([-674]), array([-1667])],\n",
              "       [array([-1667]), array([-1433])],\n",
              "       [array([-1433]), array([3036])],\n",
              "       [array([3036]), array([-5483])],\n",
              "       [array([-5483]), array([-1279])],\n",
              "       [array([-1279]), array([2159])],\n",
              "       [array([2159]), array([1933])],\n",
              "       [array([1933]), array([2766])],\n",
              "       [array([2766]), array([-3937])],\n",
              "       [array([-3937]), array([-601])],\n",
              "       [array([-601]), array([4288])],\n",
              "       [array([4288]), array([-5309])],\n",
              "       [array([-5309]), array([-1240])],\n",
              "       [array([-1240]), array([6365])],\n",
              "       [array([6365]), array([-664])],\n",
              "       [array([-664]), array([-5697])],\n",
              "       [array([-5697]), array([-1315])],\n",
              "       [array([-1315]), array([-465])],\n",
              "       [array([-465]), array([842])],\n",
              "       [array([842]), array([2963])],\n",
              "       [array([2963]), array([-2907])],\n",
              "       [array([-2907]), array([2570])],\n",
              "       [array([2570]), array([-3151])],\n",
              "       [array([-3151]), array([4013])],\n",
              "       [array([4013]), array([-6330])],\n",
              "       [array([-6330]), array([3044])],\n",
              "       [array([3044]), array([-585])],\n",
              "       [array([-585]), array([-57])],\n",
              "       [array([-57]), array([-787])],\n",
              "       [array([-787]), array([2266])],\n",
              "       [array([2266]), array([-2859])],\n",
              "       [array([-2859]), array([-438])],\n",
              "       [array([-438]), array([1897])],\n",
              "       [array([1897]), array([-2588])],\n",
              "       [array([-2588]), array([-1753])],\n",
              "       [array([-1753]), array([3472])],\n",
              "       [array([3472]), array([-1152])],\n",
              "       [array([-1152]), array([121])],\n",
              "       [array([121]), array([1491])],\n",
              "       [array([1491]), array([-2618])],\n",
              "       [array([-2618]), array([-707])],\n",
              "       [array([-707]), array([707])],\n",
              "       [array([707]), array([1431])],\n",
              "       [array([1431]), array([-353])],\n",
              "       [array([-353]), array([-3103])],\n",
              "       [array([-3103]), array([1078])],\n",
              "       [array([1078]), array([-3624])],\n",
              "       [array([-3624]), array([3724])],\n",
              "       [array([3724]), array([-271])],\n",
              "       [array([-271]), array([710])],\n",
              "       [array([710]), array([-877])],\n",
              "       [array([-877]), array([-973])],\n",
              "       [array([-973]), array([4280])],\n",
              "       [array([4280]), array([-2628])],\n",
              "       [array([-2628]), array([271])],\n",
              "       [array([271]), array([-2339])],\n",
              "       [array([-2339]), array([151])],\n",
              "       [array([151]), array([3037])],\n",
              "       [array([3037]), array([-2021])],\n",
              "       [array([-2021]), array([-3475])],\n",
              "       [array([-3475]), array([-1027])],\n",
              "       [array([-1027]), array([4067])],\n",
              "       [array([4067]), array([-621])],\n",
              "       [array([-621]), array([1683])],\n",
              "       [array([1683]), array([-3440])],\n",
              "       [array([-3440]), array([3821])],\n",
              "       [array([3821]), array([-4533])],\n",
              "       [array([-4533]), array([827])],\n",
              "       [array([827]), array([715])],\n",
              "       [array([715]), array([1])],\n",
              "       [array([1]), array([-1742])],\n",
              "       [array([-1742]), array([970])],\n",
              "       [array([970]), array([210])],\n",
              "       [array([210]), array([-2935])],\n",
              "       [array([-2935]), array([-1350])],\n",
              "       [array([-1350]), array([1260])],\n",
              "       [array([1260]), array([350])],\n",
              "       [array([350]), array([2645])],\n",
              "       [array([2645]), array([1202])],\n",
              "       [array([1202]), array([3965])],\n",
              "       [array([3965]), array([-3891])],\n",
              "       [array([-3891]), array([-316])],\n",
              "       [array([-316]), array([1948])],\n",
              "       [array([1948]), array([-3773])],\n",
              "       [array([-3773]), array([699])],\n",
              "       [array([699]), array([2479])],\n",
              "       [array([2479]), array([-2946])],\n",
              "       [array([-2946]), array([1268])],\n",
              "       [array([1268]), array([-3783])],\n",
              "       [array([-3783]), array([2712])],\n",
              "       [array([2712]), array([-721])],\n",
              "       [array([-721]), array([370])],\n",
              "       [array([370]), array([-878])],\n",
              "       [array([-878]), array([746])],\n",
              "       [array([746]), array([-3021])],\n",
              "       [array([-3021]), array([1886])],\n",
              "       [array([1886]), array([2200])],\n",
              "       [array([2200]), array([-274])],\n",
              "       [array([-274]), array([-1079])],\n",
              "       [array([-1079]), array([1587])],\n",
              "       [array([1587]), array([-3496])],\n",
              "       [array([-3496]), array([-2121])],\n",
              "       [array([-2121]), array([1503])],\n",
              "       [array([1503]), array([-1530])],\n",
              "       [array([-1530]), array([1697])],\n",
              "       [array([1697]), array([576])],\n",
              "       [array([576]), array([-1954])],\n",
              "       [array([-1954]), array([1709])],\n",
              "       [array([1709]), array([1497])],\n",
              "       [array([1497]), array([56])],\n",
              "       [array([56]), array([810])],\n",
              "       [array([810]), array([-2657])],\n",
              "       [array([-2657]), array([-290])],\n",
              "       [array([-290]), array([419])],\n",
              "       [array([419]), array([-104])],\n",
              "       [array([-104]), array([447])],\n",
              "       [array([447]), array([195])],\n",
              "       [array([195]), array([-332])],\n",
              "       [array([-332]), array([6])],\n",
              "       [array([6]), array([1110])],\n",
              "       [array([1110]), array([-2454])],\n",
              "       [array([-2454]), array([296])],\n",
              "       [array([296]), array([-2749])],\n",
              "       [array([-2749]), array([-484])],\n",
              "       [array([-484]), array([1826])],\n",
              "       [array([1826]), array([1004])],\n",
              "       [array([1004]), array([168])],\n",
              "       [array([168]), array([1884])],\n",
              "       [array([1884]), array([-2224])],\n",
              "       [array([-2224]), array([2413])],\n",
              "       [array([2413]), array([1325])],\n",
              "       [array([1325]), array([-4972])],\n",
              "       [array([-4972]), array([1117])],\n",
              "       [array([1117]), array([1771])],\n",
              "       [array([1771]), array([-1517])],\n",
              "       [array([-1517]), array([-1474])],\n",
              "       [array([-1474]), array([-1333])],\n",
              "       [array([-1333]), array([425])],\n",
              "       [array([425]), array([1451])],\n",
              "       [array([1451]), array([939])],\n",
              "       [array([939]), array([-1899])],\n",
              "       [array([-1899]), array([1889])],\n",
              "       [array([1889]), array([1743])],\n",
              "       [array([1743]), array([-4459])],\n",
              "       [array([-4459]), array([242])],\n",
              "       [array([242]), array([-703])],\n",
              "       [array([-703]), array([3149])],\n",
              "       [array([3149]), array([-774])],\n",
              "       [array([-774]), array([1042])],\n",
              "       [array([1042]), array([-3508])],\n",
              "       [array([-3508]), array([2184])],\n",
              "       [array([2184]), array([-1175])],\n",
              "       [array([-1175]), array([845])],\n",
              "       [array([845]), array([-2312])],\n",
              "       [array([-2312]), array([-21170])],\n",
              "       [array([-21170]), array([20059])],\n",
              "       [array([20059]), array([2018])],\n",
              "       [array([2018]), array([-773])],\n",
              "       [array([-773]), array([1704])],\n",
              "       [array([1704]), array([-2424])],\n",
              "       [array([-2424]), array([356])],\n",
              "       [array([356]), array([1390])],\n",
              "       [array([1390]), array([-3700])],\n",
              "       [array([-3700]), array([2441])],\n",
              "       [array([2441]), array([-2483])],\n",
              "       [array([-2483]), array([790])],\n",
              "       [array([790]), array([926])],\n",
              "       [array([926]), array([1228])],\n",
              "       [array([1228]), array([-3277])],\n",
              "       [array([-3277]), array([1352])],\n",
              "       [array([1352]), array([677])],\n",
              "       [array([677]), array([-517])],\n",
              "       [array([-517]), array([-170])],\n",
              "       [array([-170]), array([3844])],\n",
              "       [array([3844]), array([-1873])],\n",
              "       [array([-1873]), array([-1957])],\n",
              "       [array([-1957]), array([-1690])],\n",
              "       [array([-1690]), array([1447])],\n",
              "       [array([1447]), array([-1656])],\n",
              "       [array([-1656]), array([-4727])],\n",
              "       [array([-4727]), array([4457])],\n",
              "       [array([4457]), array([868])],\n",
              "       [array([868]), array([-719])],\n",
              "       [array([-719]), array([-159])],\n",
              "       [array([-159]), array([1203])],\n",
              "       [array([1203]), array([-824])]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7:3切分训练集与测试集\n",
        "testNum=108\n",
        "train,test=supervised_value[:-testNum],supervised_value[-testNum:]"
      ],
      "metadata": {
        "id": "wwh2t3XdjWDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train"
      ],
      "metadata": {
        "id": "SRjVZCZmwZ6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test"
      ],
      "metadata": {
        "id": "pcszWE4nwiR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正则化于-1,1\n",
        "def scale(train,test):\n",
        "    # 创建一个缩放器，将数据集中的数据缩放到[-1,1]的取值范围中\n",
        "    scaler=MinMaxScaler(feature_range=(-1,1))\n",
        "    # 使用数据来训练缩放器\n",
        "    scaler=scaler.fit(train)\n",
        "    # 使用缩放器来将训练集和测试集进行缩放\n",
        "    train_scaled=scaler.transform(train)\n",
        "    test_scaled=scaler.transform(test)\n",
        "    return scaler,train_scaled,test_scaled\n",
        " \n",
        "scaler,train_scaled,test_scaled=scale(train,test)\n",
        "print('train_scaled',train_scaled)\n",
        "print('test_scaled',test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuISv-5JjybU",
        "outputId": "6be2a0b5-b7e7-402e-eef9-915b1b3d6c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_scaled [[ 0.12528127  0.43125399]\n",
            " [ 0.43125399 -0.02168767]\n",
            " [-0.02168767  0.35479379]\n",
            " [ 0.35479379  0.81052061]\n",
            " [ 0.81052061 -0.1135689 ]\n",
            " [-0.1135689   0.05403959]\n",
            " [ 0.05403959  0.66410871]\n",
            " [ 0.66410871  0.65880223]\n",
            " [ 0.65880223  0.17994386]\n",
            " [ 0.17994386  0.30980599]\n",
            " [ 0.30980599  0.10700177]\n",
            " [ 0.10700177  1.        ]\n",
            " [ 1.         -0.4120803 ]\n",
            " [-0.4120803   0.56157054]\n",
            " [ 0.56157054 -0.34728849]\n",
            " [-0.34728849  0.54217698]\n",
            " [ 0.54217698 -0.04902629]\n",
            " [-0.04902629  0.39450442]\n",
            " [ 0.39450442  0.50558866]\n",
            " [ 0.50558866  0.55765665]\n",
            " [ 0.55765665 -0.38595835]\n",
            " [-0.38595835  0.36351576]\n",
            " [ 0.36351576 -0.14638991]\n",
            " [-0.14638991  0.80877621]\n",
            " [ 0.80877621  0.27698498]\n",
            " [ 0.27698498  0.27546047]\n",
            " [ 0.27546047  0.0705747 ]\n",
            " [ 0.0705747   0.14731341]\n",
            " [ 0.14731341 -0.46079143]\n",
            " [-0.46079143 -0.00195695]\n",
            " [-0.00195695 -0.20879234]\n",
            " [-0.20879234  0.82901999]\n",
            " [ 0.82901999 -0.32714733]\n",
            " [-0.32714733  0.11733621]\n",
            " [ 0.11733621 -0.25590566]\n",
            " [-0.25590566 -0.00578289]\n",
            " [-0.00578289  0.23648277]\n",
            " [ 0.23648277 -0.10852628]\n",
            " [-0.10852628  0.51102707]\n",
            " [ 0.51102707  0.15291307]\n",
            " [ 0.15291307  0.89167161]\n",
            " [ 0.89167161 -1.        ]\n",
            " [-1.          0.37578516]\n",
            " [ 0.37578516 -0.00695559]\n",
            " [-0.00695559  0.20480515]\n",
            " [ 0.20480515  0.53023007]\n",
            " [ 0.53023007 -0.29659843]\n",
            " [-0.29659843 -0.26906924]\n",
            " [-0.26906924  0.20199066]\n",
            " [ 0.20199066  0.01469543]\n",
            " [ 0.01469543  0.15533176]\n",
            " [ 0.15533176  0.13526389]\n",
            " [ 0.13526389 -0.03533499]\n",
            " [-0.03533499  0.37692855]\n",
            " [ 0.37692855 -0.12811041]\n",
            " [-0.12811041 -0.40665655]\n",
            " [-0.40665655  0.50882825]\n",
            " [ 0.50882825 -0.04036295]\n",
            " [-0.04036295  0.12528127]\n",
            " [ 0.12528127 -0.03775369]\n",
            " [-0.03775369  0.04210735]\n",
            " [ 0.04210735  0.22913872]\n",
            " [ 0.22913872  0.38129686]\n",
            " [ 0.38129686 -0.3775149 ]\n",
            " [-0.3775149  -0.05960993]\n",
            " [-0.05960993  0.21279418]\n",
            " [ 0.21279418  0.38106232]\n",
            " [ 0.38106232  0.34517763]\n",
            " [ 0.34517763 -0.58984733]\n",
            " [-0.58984733  0.28299508]\n",
            " [ 0.28299508 -0.21947859]\n",
            " [-0.21947859  0.10587304]\n",
            " [ 0.10587304  0.39865286]\n",
            " [ 0.39865286 -0.0722458 ]\n",
            " [-0.0722458   0.07579322]\n",
            " [ 0.07579322  0.30530575]\n",
            " [ 0.30530575 -0.15131526]\n",
            " [-0.15131526  0.11516671]\n",
            " [ 0.11516671  0.35925006]\n",
            " [ 0.35925006  0.24589371]\n",
            " [ 0.24589371 -0.23570586]\n",
            " [-0.23570586  0.25822174]\n",
            " [ 0.25822174 -0.21069798]\n",
            " [-0.21069798  0.2634989 ]\n",
            " [ 0.2634989   0.278187  ]\n",
            " [ 0.278187   -0.32250049]\n",
            " [-0.32250049  0.20031956]\n",
            " [ 0.20031956  0.00368668]\n",
            " [ 0.00368668  0.07397553]\n",
            " [ 0.07397553  0.12388868]\n",
            " [ 0.12388868  0.46825275]\n",
            " [ 0.46825275  0.02343206]\n",
            " [ 0.02343206  0.00846545]\n",
            " [ 0.00846545 -0.11531329]\n",
            " [-0.11531329  0.19973321]\n",
            " [ 0.19973321  0.24765276]\n",
            " [ 0.24765276 -0.01847739]\n",
            " [-0.01847739  0.36778147]\n",
            " [ 0.36778147 -0.19727054]\n",
            " [-0.19727054  0.1061369 ]\n",
            " [ 0.1061369   0.20886563]\n",
            " [ 0.20886563  0.07421007]\n",
            " [ 0.07421007  0.02425295]\n",
            " [ 0.02425295  0.06588389]\n",
            " [ 0.06588389  0.43717613]\n",
            " [ 0.43717613 -0.22169206]\n",
            " [-0.22169206  0.15298636]\n",
            " [ 0.15298636  0.03873583]\n",
            " [ 0.03873583  0.29539641]\n",
            " [ 0.29539641  0.06391961]\n",
            " [ 0.06391961 -0.02120393]\n",
            " [-0.02120393  0.38441918]\n",
            " [ 0.38441918 -0.29485404]\n",
            " [-0.29485404  0.12039989]\n",
            " [ 0.12039989  0.38891943]\n",
            " [ 0.38891943 -0.01875591]\n",
            " [-0.01875591  0.44679229]\n",
            " [ 0.44679229 -0.19385504]\n",
            " [-0.19385504 -0.01671834]\n",
            " [-0.01671834  0.09839706]\n",
            " [ 0.09839706  0.09684323]\n",
            " [ 0.09684323  0.36589048]\n",
            " [ 0.36589048 -0.08756422]\n",
            " [-0.08756422  0.19907357]\n",
            " [ 0.19907357  0.06997369]\n",
            " [ 0.06997369  0.15330885]\n",
            " [ 0.15330885  0.06136898]\n",
            " [ 0.06136898  0.03571612]\n",
            " [ 0.03571612  0.1433702 ]\n",
            " [ 0.1433702   0.16006655]\n",
            " [ 0.16006655  0.17235061]\n",
            " [ 0.17235061  0.08111436]\n",
            " [ 0.08111436  0.11009477]\n",
            " [ 0.11009477  0.08027881]\n",
            " [ 0.08027881  0.14133263]\n",
            " [ 0.14133263  0.10361559]\n",
            " [ 0.10361559  0.08055733]\n",
            " [ 0.08055733  0.11565045]\n",
            " [ 0.11565045  0.1320976 ]\n",
            " [ 0.1320976   0.13492674]\n",
            " [ 0.13492674  0.06991505]\n",
            " [ 0.06991505  0.07793341]\n",
            " [ 0.07793341  0.18582203]\n",
            " [ 0.18582203  0.15165241]\n",
            " [ 0.15165241  0.13221487]\n",
            " [ 0.13221487  0.09650608]\n",
            " [ 0.09650608  0.18615918]\n",
            " [ 0.18615918  0.02020713]\n",
            " [ 0.02020713  0.10292663]\n",
            " [ 0.10292663  0.15078754]\n",
            " [ 0.15078754  0.13280122]\n",
            " [ 0.13280122  0.15511188]\n",
            " [ 0.15511188  0.11053453]\n",
            " [ 0.11053453  0.05720589]\n",
            " [ 0.05720589  0.07517755]\n",
            " [ 0.07517755  0.19455866]\n",
            " [ 0.19455866  0.08303466]\n",
            " [ 0.08303466  0.2156673 ]\n",
            " [ 0.2156673   0.06695398]\n",
            " [ 0.06695398  0.08776945]\n",
            " [ 0.08776945  0.14338486]\n",
            " [ 0.14338486  0.01592676]\n",
            " [ 0.01592676  0.24480896]\n",
            " [ 0.24480896  0.05381971]\n",
            " [ 0.05381971  0.16717606]\n",
            " [ 0.16717606  0.04177019]\n",
            " [ 0.04177019  0.20540616]\n",
            " [ 0.20540616  0.08872227]\n",
            " [ 0.08872227  0.05890631]\n",
            " [ 0.05890631  0.18920821]\n",
            " [ 0.18920821  0.08916203]\n",
            " [ 0.08916203  0.11540125]\n",
            " [ 0.11540125  0.10084508]\n",
            " [ 0.10084508  0.10427523]\n",
            " [ 0.10427523  0.16978532]\n",
            " [ 0.16978532  0.04490717]\n",
            " [ 0.04490717  0.10653269]\n",
            " [ 0.10653269  0.15692957]\n",
            " [ 0.15692957  0.15361669]\n",
            " [ 0.15361669  0.16582745]\n",
            " [ 0.16582745  0.06756965]\n",
            " [ 0.06756965  0.11647134]\n",
            " [ 0.11647134  0.18813812]\n",
            " [ 0.18813812  0.0474578 ]\n",
            " [ 0.0474578   0.10710438]\n",
            " [ 0.10710438  0.2185844 ]\n",
            " [ 0.2185844   0.11554784]\n",
            " [ 0.11554784  0.04177019]\n",
            " [ 0.04177019  0.10600497]\n",
            " [ 0.10600497  0.11846493]\n",
            " [ 0.11846493  0.13762396]\n",
            " [ 0.13762396  0.16871523]\n",
            " [ 0.16871523  0.08266819]\n",
            " [ 0.08266819  0.16295433]\n",
            " [ 0.16295433  0.07909145]\n",
            " [ 0.07909145  0.18410695]\n",
            " [ 0.18410695  0.03249119]\n",
            " [ 0.03249119  0.16990259]\n",
            " [ 0.16990259  0.11670588]\n",
            " [ 0.11670588  0.12444571]\n",
            " [ 0.12444571  0.11374481]\n",
            " [ 0.11374481  0.15849806]\n",
            " [ 0.15849806  0.08337181]\n",
            " [ 0.08337181  0.11886072]\n",
            " [ 0.11886072  0.15308897]\n",
            " [ 0.15308897  0.08734434]\n",
            " [ 0.08734434  0.09958442]\n",
            " [ 0.09958442  0.17617655]\n",
            " [ 0.17617655  0.10839435]\n",
            " [ 0.10839435  0.12705498]\n",
            " [ 0.12705498  0.14713751]\n",
            " [ 0.14713751  0.08690458]\n",
            " [ 0.08690458  0.11491751]\n",
            " [ 0.11491751  0.13564502]\n",
            " [ 0.13564502  0.14625798]\n",
            " [ 0.14625798  0.12010672]\n",
            " [ 0.12010672  0.07979507]\n",
            " [ 0.07979507  0.14108343]\n",
            " [ 0.14108343  0.07215785]\n",
            " [ 0.07215785  0.17987056]\n",
            " [ 0.17987056  0.12130874]\n",
            " [ 0.12130874  0.135689  ]\n",
            " [ 0.135689    0.11242552]\n",
            " [ 0.11242552  0.11101827]\n",
            " [ 0.11101827  0.18802084]\n",
            " [ 0.18802084  0.08675799]\n",
            " [ 0.08675799  0.12925379]\n",
            " [ 0.12925379  0.09099438]\n",
            " [ 0.09099438  0.12749474]\n",
            " [ 0.12749474  0.16979998]\n",
            " [ 0.16979998  0.09565587]\n",
            " [ 0.09565587  0.074342  ]\n",
            " [ 0.074342    0.1102267 ]\n",
            " [ 0.1102267   0.18489852]\n",
            " [ 0.18489852  0.11617816]\n",
            " [ 0.11617816  0.14995199]\n",
            " [ 0.14995199  0.07485506]\n",
            " [ 0.07485506  0.18129246]\n",
            " [ 0.18129246  0.05883301]\n",
            " [ 0.05883301  0.13740408]\n",
            " [ 0.13740408  0.13576229]\n",
            " [ 0.13576229  0.12529592]\n",
            " [ 0.12529592  0.09974567]\n",
            " [ 0.09974567  0.13950028]\n",
            " [ 0.13950028  0.12835961]\n",
            " [ 0.12835961  0.08225775]\n",
            " [ 0.08225775  0.10549191]\n",
            " [ 0.10549191  0.14375133]\n",
            " [ 0.14375133  0.13041184]\n",
            " [ 0.13041184  0.16405374]]\n",
            "test_scaled [[ 0.16405374  0.14290112]\n",
            " [ 0.14290112  0.18340333]\n",
            " [ 0.18340333  0.06824395]\n",
            " [ 0.06824395  0.12064909]\n",
            " [ 0.12064909  0.15383657]\n",
            " [ 0.15383657  0.06997369]\n",
            " [ 0.06997369  0.13552775]\n",
            " [ 0.13552775  0.16162038]\n",
            " [ 0.16162038  0.0820965 ]\n",
            " [ 0.0820965   0.1438686 ]\n",
            " [ 0.1438686   0.0698271 ]\n",
            " [ 0.0698271   0.16503588]\n",
            " [ 0.16503588  0.11471228]\n",
            " [ 0.11471228  0.13070501]\n",
            " [ 0.13070501  0.11241086]\n",
            " [ 0.11241086  0.13621672]\n",
            " [ 0.13621672  0.08099709]\n",
            " [ 0.08099709  0.15292772]\n",
            " [ 0.15292772  0.15753058]\n",
            " [ 0.15753058  0.12126476]\n",
            " [ 0.12126476  0.10946444]\n",
            " [ 0.10946444  0.14854475]\n",
            " [ 0.14854475  0.07403417]\n",
            " [ 0.07403417  0.09418999]\n",
            " [ 0.09418999  0.14731341]\n",
            " [ 0.14731341  0.10285333]\n",
            " [ 0.10285333  0.15015722]\n",
            " [ 0.15015722  0.13372472]\n",
            " [ 0.13372472  0.09663801]\n",
            " [ 0.09663801  0.15033312]\n",
            " [ 0.15033312  0.14722546]\n",
            " [ 0.14722546  0.12610216]\n",
            " [ 0.12610216  0.13715488]\n",
            " [ 0.13715488  0.08633289]\n",
            " [ 0.08633289  0.12103022]\n",
            " [ 0.12103022  0.13142329]\n",
            " [ 0.13142329  0.12375675]\n",
            " [ 0.12375675  0.13183374]\n",
            " [ 0.13183374  0.12813973]\n",
            " [ 0.12813973  0.12041455]\n",
            " [ 0.12041455  0.12536922]\n",
            " [ 0.12536922  0.14155251]\n",
            " [ 0.14155251  0.08930862]\n",
            " [ 0.08930862  0.12962026]\n",
            " [ 0.12962026  0.08498428]\n",
            " [ 0.08498428  0.11818642]\n",
            " [ 0.11818642  0.1520482 ]\n",
            " [ 0.1520482   0.13999868]\n",
            " [ 0.13999868  0.12774394]\n",
            " [ 0.12774394  0.15289841]\n",
            " [ 0.15289841  0.09268014]\n",
            " [ 0.09268014  0.1606529 ]\n",
            " [ 0.1606529   0.14470415]\n",
            " [ 0.14470415  0.05239781]\n",
            " [ 0.05239781  0.14165512]\n",
            " [ 0.14165512  0.15124197]\n",
            " [ 0.15124197  0.1030439 ]\n",
            " [ 0.1030439   0.10367422]\n",
            " [ 0.10367422  0.10574111]\n",
            " [ 0.10574111  0.13151125]\n",
            " [ 0.13151125  0.14655116]\n",
            " [ 0.14655116  0.13904586]\n",
            " [ 0.13904586  0.09744424]\n",
            " [ 0.09744424  0.1529717 ]\n",
            " [ 0.1529717   0.15083152]\n",
            " [ 0.15083152  0.05991776]\n",
            " [ 0.05991776  0.12882869]\n",
            " [ 0.12882869  0.11497614]\n",
            " [ 0.11497614  0.17144176]\n",
            " [ 0.17144176  0.11393537]\n",
            " [ 0.11393537  0.14055571]\n",
            " [ 0.14055571  0.07385826]\n",
            " [ 0.07385826  0.15729604]\n",
            " [ 0.15729604  0.1080572 ]\n",
            " [ 0.1080572   0.13766793]\n",
            " [ 0.13766793  0.09139017]\n",
            " [ 0.09139017 -0.18504511]\n",
            " [-0.18504511  0.41932174]\n",
            " [ 0.41932174  0.15486268]\n",
            " [ 0.15486268  0.11395003]\n",
            " [ 0.11395003  0.15025983]\n",
            " [ 0.15025983  0.08974838]\n",
            " [ 0.08974838  0.13049979]\n",
            " [ 0.13049979  0.14565697]\n",
            " [ 0.14565697  0.07104378]\n",
            " [ 0.07104378  0.16106335]\n",
            " [ 0.16106335  0.08888351]\n",
            " [ 0.08888351  0.1368617 ]\n",
            " [ 0.1368617   0.1388553 ]\n",
            " [ 0.1388553   0.14328225]\n",
            " [ 0.14328225  0.07724444]\n",
            " [ 0.07724444  0.14509994]\n",
            " [ 0.14509994  0.13520526]\n",
            " [ 0.13520526  0.11770268]\n",
            " [ 0.11770268  0.12278927]\n",
            " [ 0.12278927  0.18162962]\n",
            " [ 0.18162962  0.09782537]\n",
            " [ 0.09782537  0.09659403]\n",
            " [ 0.09659403  0.10050793]\n",
            " [ 0.10050793  0.14649252]\n",
            " [ 0.14649252  0.10100633]\n",
            " [ 0.10100633  0.05598921]\n",
            " [ 0.05598921  0.19061545]\n",
            " [ 0.19061545  0.13800509]\n",
            " [ 0.13800509  0.1147416 ]\n",
            " [ 0.1147416   0.12295052]\n",
            " [ 0.12295052  0.14291578]\n",
            " [ 0.14291578  0.11320243]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 训练LSTM模型"
      ],
      "metadata": {
        "id": "Wg2emkU5kLMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 将训练集中的输入和输出两列分为x和y，并将输入列转换为三维数组\n",
        "# X,y=train[:,0:-1],train[:,-1]\n",
        "X,y=train_scaled[:,0:-1],train_scaled[:,-1]\n",
        "X=X.reshape(X.shape[0],1,X.shape[1])\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QQ3g7fHkKCL",
        "outputId": "f6766722-f62d-49f4-85da-1524d23d5025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.12528127]],\n",
              "\n",
              "       [[ 0.43125399]],\n",
              "\n",
              "       [[-0.02168767]],\n",
              "\n",
              "       [[ 0.35479379]],\n",
              "\n",
              "       [[ 0.81052061]],\n",
              "\n",
              "       [[-0.1135689 ]],\n",
              "\n",
              "       [[ 0.05403959]],\n",
              "\n",
              "       [[ 0.66410871]],\n",
              "\n",
              "       [[ 0.65880223]],\n",
              "\n",
              "       [[ 0.17994386]],\n",
              "\n",
              "       [[ 0.30980599]],\n",
              "\n",
              "       [[ 0.10700177]],\n",
              "\n",
              "       [[ 1.        ]],\n",
              "\n",
              "       [[-0.4120803 ]],\n",
              "\n",
              "       [[ 0.56157054]],\n",
              "\n",
              "       [[-0.34728849]],\n",
              "\n",
              "       [[ 0.54217698]],\n",
              "\n",
              "       [[-0.04902629]],\n",
              "\n",
              "       [[ 0.39450442]],\n",
              "\n",
              "       [[ 0.50558866]],\n",
              "\n",
              "       [[ 0.55765665]],\n",
              "\n",
              "       [[-0.38595835]],\n",
              "\n",
              "       [[ 0.36351576]],\n",
              "\n",
              "       [[-0.14638991]],\n",
              "\n",
              "       [[ 0.80877621]],\n",
              "\n",
              "       [[ 0.27698498]],\n",
              "\n",
              "       [[ 0.27546047]],\n",
              "\n",
              "       [[ 0.0705747 ]],\n",
              "\n",
              "       [[ 0.14731341]],\n",
              "\n",
              "       [[-0.46079143]],\n",
              "\n",
              "       [[-0.00195695]],\n",
              "\n",
              "       [[-0.20879234]],\n",
              "\n",
              "       [[ 0.82901999]],\n",
              "\n",
              "       [[-0.32714733]],\n",
              "\n",
              "       [[ 0.11733621]],\n",
              "\n",
              "       [[-0.25590566]],\n",
              "\n",
              "       [[-0.00578289]],\n",
              "\n",
              "       [[ 0.23648277]],\n",
              "\n",
              "       [[-0.10852628]],\n",
              "\n",
              "       [[ 0.51102707]],\n",
              "\n",
              "       [[ 0.15291307]],\n",
              "\n",
              "       [[ 0.89167161]],\n",
              "\n",
              "       [[-1.        ]],\n",
              "\n",
              "       [[ 0.37578516]],\n",
              "\n",
              "       [[-0.00695559]],\n",
              "\n",
              "       [[ 0.20480515]],\n",
              "\n",
              "       [[ 0.53023007]],\n",
              "\n",
              "       [[-0.29659843]],\n",
              "\n",
              "       [[-0.26906924]],\n",
              "\n",
              "       [[ 0.20199066]],\n",
              "\n",
              "       [[ 0.01469543]],\n",
              "\n",
              "       [[ 0.15533176]],\n",
              "\n",
              "       [[ 0.13526389]],\n",
              "\n",
              "       [[-0.03533499]],\n",
              "\n",
              "       [[ 0.37692855]],\n",
              "\n",
              "       [[-0.12811041]],\n",
              "\n",
              "       [[-0.40665655]],\n",
              "\n",
              "       [[ 0.50882825]],\n",
              "\n",
              "       [[-0.04036295]],\n",
              "\n",
              "       [[ 0.12528127]],\n",
              "\n",
              "       [[-0.03775369]],\n",
              "\n",
              "       [[ 0.04210735]],\n",
              "\n",
              "       [[ 0.22913872]],\n",
              "\n",
              "       [[ 0.38129686]],\n",
              "\n",
              "       [[-0.3775149 ]],\n",
              "\n",
              "       [[-0.05960993]],\n",
              "\n",
              "       [[ 0.21279418]],\n",
              "\n",
              "       [[ 0.38106232]],\n",
              "\n",
              "       [[ 0.34517763]],\n",
              "\n",
              "       [[-0.58984733]],\n",
              "\n",
              "       [[ 0.28299508]],\n",
              "\n",
              "       [[-0.21947859]],\n",
              "\n",
              "       [[ 0.10587304]],\n",
              "\n",
              "       [[ 0.39865286]],\n",
              "\n",
              "       [[-0.0722458 ]],\n",
              "\n",
              "       [[ 0.07579322]],\n",
              "\n",
              "       [[ 0.30530575]],\n",
              "\n",
              "       [[-0.15131526]],\n",
              "\n",
              "       [[ 0.11516671]],\n",
              "\n",
              "       [[ 0.35925006]],\n",
              "\n",
              "       [[ 0.24589371]],\n",
              "\n",
              "       [[-0.23570586]],\n",
              "\n",
              "       [[ 0.25822174]],\n",
              "\n",
              "       [[-0.21069798]],\n",
              "\n",
              "       [[ 0.2634989 ]],\n",
              "\n",
              "       [[ 0.278187  ]],\n",
              "\n",
              "       [[-0.32250049]],\n",
              "\n",
              "       [[ 0.20031956]],\n",
              "\n",
              "       [[ 0.00368668]],\n",
              "\n",
              "       [[ 0.07397553]],\n",
              "\n",
              "       [[ 0.12388868]],\n",
              "\n",
              "       [[ 0.46825275]],\n",
              "\n",
              "       [[ 0.02343206]],\n",
              "\n",
              "       [[ 0.00846545]],\n",
              "\n",
              "       [[-0.11531329]],\n",
              "\n",
              "       [[ 0.19973321]],\n",
              "\n",
              "       [[ 0.24765276]],\n",
              "\n",
              "       [[-0.01847739]],\n",
              "\n",
              "       [[ 0.36778147]],\n",
              "\n",
              "       [[-0.19727054]],\n",
              "\n",
              "       [[ 0.1061369 ]],\n",
              "\n",
              "       [[ 0.20886563]],\n",
              "\n",
              "       [[ 0.07421007]],\n",
              "\n",
              "       [[ 0.02425295]],\n",
              "\n",
              "       [[ 0.06588389]],\n",
              "\n",
              "       [[ 0.43717613]],\n",
              "\n",
              "       [[-0.22169206]],\n",
              "\n",
              "       [[ 0.15298636]],\n",
              "\n",
              "       [[ 0.03873583]],\n",
              "\n",
              "       [[ 0.29539641]],\n",
              "\n",
              "       [[ 0.06391961]],\n",
              "\n",
              "       [[-0.02120393]],\n",
              "\n",
              "       [[ 0.38441918]],\n",
              "\n",
              "       [[-0.29485404]],\n",
              "\n",
              "       [[ 0.12039989]],\n",
              "\n",
              "       [[ 0.38891943]],\n",
              "\n",
              "       [[-0.01875591]],\n",
              "\n",
              "       [[ 0.44679229]],\n",
              "\n",
              "       [[-0.19385504]],\n",
              "\n",
              "       [[-0.01671834]],\n",
              "\n",
              "       [[ 0.09839706]],\n",
              "\n",
              "       [[ 0.09684323]],\n",
              "\n",
              "       [[ 0.36589048]],\n",
              "\n",
              "       [[-0.08756422]],\n",
              "\n",
              "       [[ 0.19907357]],\n",
              "\n",
              "       [[ 0.06997369]],\n",
              "\n",
              "       [[ 0.15330885]],\n",
              "\n",
              "       [[ 0.06136898]],\n",
              "\n",
              "       [[ 0.03571612]],\n",
              "\n",
              "       [[ 0.1433702 ]],\n",
              "\n",
              "       [[ 0.16006655]],\n",
              "\n",
              "       [[ 0.17235061]],\n",
              "\n",
              "       [[ 0.08111436]],\n",
              "\n",
              "       [[ 0.11009477]],\n",
              "\n",
              "       [[ 0.08027881]],\n",
              "\n",
              "       [[ 0.14133263]],\n",
              "\n",
              "       [[ 0.10361559]],\n",
              "\n",
              "       [[ 0.08055733]],\n",
              "\n",
              "       [[ 0.11565045]],\n",
              "\n",
              "       [[ 0.1320976 ]],\n",
              "\n",
              "       [[ 0.13492674]],\n",
              "\n",
              "       [[ 0.06991505]],\n",
              "\n",
              "       [[ 0.07793341]],\n",
              "\n",
              "       [[ 0.18582203]],\n",
              "\n",
              "       [[ 0.15165241]],\n",
              "\n",
              "       [[ 0.13221487]],\n",
              "\n",
              "       [[ 0.09650608]],\n",
              "\n",
              "       [[ 0.18615918]],\n",
              "\n",
              "       [[ 0.02020713]],\n",
              "\n",
              "       [[ 0.10292663]],\n",
              "\n",
              "       [[ 0.15078754]],\n",
              "\n",
              "       [[ 0.13280122]],\n",
              "\n",
              "       [[ 0.15511188]],\n",
              "\n",
              "       [[ 0.11053453]],\n",
              "\n",
              "       [[ 0.05720589]],\n",
              "\n",
              "       [[ 0.07517755]],\n",
              "\n",
              "       [[ 0.19455866]],\n",
              "\n",
              "       [[ 0.08303466]],\n",
              "\n",
              "       [[ 0.2156673 ]],\n",
              "\n",
              "       [[ 0.06695398]],\n",
              "\n",
              "       [[ 0.08776945]],\n",
              "\n",
              "       [[ 0.14338486]],\n",
              "\n",
              "       [[ 0.01592676]],\n",
              "\n",
              "       [[ 0.24480896]],\n",
              "\n",
              "       [[ 0.05381971]],\n",
              "\n",
              "       [[ 0.16717606]],\n",
              "\n",
              "       [[ 0.04177019]],\n",
              "\n",
              "       [[ 0.20540616]],\n",
              "\n",
              "       [[ 0.08872227]],\n",
              "\n",
              "       [[ 0.05890631]],\n",
              "\n",
              "       [[ 0.18920821]],\n",
              "\n",
              "       [[ 0.08916203]],\n",
              "\n",
              "       [[ 0.11540125]],\n",
              "\n",
              "       [[ 0.10084508]],\n",
              "\n",
              "       [[ 0.10427523]],\n",
              "\n",
              "       [[ 0.16978532]],\n",
              "\n",
              "       [[ 0.04490717]],\n",
              "\n",
              "       [[ 0.10653269]],\n",
              "\n",
              "       [[ 0.15692957]],\n",
              "\n",
              "       [[ 0.15361669]],\n",
              "\n",
              "       [[ 0.16582745]],\n",
              "\n",
              "       [[ 0.06756965]],\n",
              "\n",
              "       [[ 0.11647134]],\n",
              "\n",
              "       [[ 0.18813812]],\n",
              "\n",
              "       [[ 0.0474578 ]],\n",
              "\n",
              "       [[ 0.10710438]],\n",
              "\n",
              "       [[ 0.2185844 ]],\n",
              "\n",
              "       [[ 0.11554784]],\n",
              "\n",
              "       [[ 0.04177019]],\n",
              "\n",
              "       [[ 0.10600497]],\n",
              "\n",
              "       [[ 0.11846493]],\n",
              "\n",
              "       [[ 0.13762396]],\n",
              "\n",
              "       [[ 0.16871523]],\n",
              "\n",
              "       [[ 0.08266819]],\n",
              "\n",
              "       [[ 0.16295433]],\n",
              "\n",
              "       [[ 0.07909145]],\n",
              "\n",
              "       [[ 0.18410695]],\n",
              "\n",
              "       [[ 0.03249119]],\n",
              "\n",
              "       [[ 0.16990259]],\n",
              "\n",
              "       [[ 0.11670588]],\n",
              "\n",
              "       [[ 0.12444571]],\n",
              "\n",
              "       [[ 0.11374481]],\n",
              "\n",
              "       [[ 0.15849806]],\n",
              "\n",
              "       [[ 0.08337181]],\n",
              "\n",
              "       [[ 0.11886072]],\n",
              "\n",
              "       [[ 0.15308897]],\n",
              "\n",
              "       [[ 0.08734434]],\n",
              "\n",
              "       [[ 0.09958442]],\n",
              "\n",
              "       [[ 0.17617655]],\n",
              "\n",
              "       [[ 0.10839435]],\n",
              "\n",
              "       [[ 0.12705498]],\n",
              "\n",
              "       [[ 0.14713751]],\n",
              "\n",
              "       [[ 0.08690458]],\n",
              "\n",
              "       [[ 0.11491751]],\n",
              "\n",
              "       [[ 0.13564502]],\n",
              "\n",
              "       [[ 0.14625798]],\n",
              "\n",
              "       [[ 0.12010672]],\n",
              "\n",
              "       [[ 0.07979507]],\n",
              "\n",
              "       [[ 0.14108343]],\n",
              "\n",
              "       [[ 0.07215785]],\n",
              "\n",
              "       [[ 0.17987056]],\n",
              "\n",
              "       [[ 0.12130874]],\n",
              "\n",
              "       [[ 0.135689  ]],\n",
              "\n",
              "       [[ 0.11242552]],\n",
              "\n",
              "       [[ 0.11101827]],\n",
              "\n",
              "       [[ 0.18802084]],\n",
              "\n",
              "       [[ 0.08675799]],\n",
              "\n",
              "       [[ 0.12925379]],\n",
              "\n",
              "       [[ 0.09099438]],\n",
              "\n",
              "       [[ 0.12749474]],\n",
              "\n",
              "       [[ 0.16979998]],\n",
              "\n",
              "       [[ 0.09565587]],\n",
              "\n",
              "       [[ 0.074342  ]],\n",
              "\n",
              "       [[ 0.1102267 ]],\n",
              "\n",
              "       [[ 0.18489852]],\n",
              "\n",
              "       [[ 0.11617816]],\n",
              "\n",
              "       [[ 0.14995199]],\n",
              "\n",
              "       [[ 0.07485506]],\n",
              "\n",
              "       [[ 0.18129246]],\n",
              "\n",
              "       [[ 0.05883301]],\n",
              "\n",
              "       [[ 0.13740408]],\n",
              "\n",
              "       [[ 0.13576229]],\n",
              "\n",
              "       [[ 0.12529592]],\n",
              "\n",
              "       [[ 0.09974567]],\n",
              "\n",
              "       [[ 0.13950028]],\n",
              "\n",
              "       [[ 0.12835961]],\n",
              "\n",
              "       [[ 0.08225775]],\n",
              "\n",
              "       [[ 0.10549191]],\n",
              "\n",
              "       [[ 0.14375133]],\n",
              "\n",
              "       [[ 0.13041184]]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化LSTM模型并开始训练，设置神经元核心的个数，设置训练时输入数据的格式等等\n",
        "def fit_lstm(train,batch_size,nb_epoch,neurons):\n",
        "    # 将数据对中的x和y分开\n",
        "    X,y=train[:,0:-1],train[:,-1]\n",
        "    # 将2D数据拼接成3D数据，形状为[N*1*1]\n",
        "    X=X.reshape(X.shape[0],1,X.shape[1])\n",
        " \n",
        "    model=Sequential()\n",
        "    model.add(LSTM(neurons,batch_input_shape=(batch_size,X.shape[1],X.shape[2]),stateful=True))\n",
        "    model.add(Dense(1))\n",
        " \n",
        "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
        "    for i in range(nb_epoch):\n",
        "        # shuffle是不混淆数据顺序\n",
        "        his=model.fit(X,y,batch_size=batch_size,verbose=1,shuffle=False)\n",
        "        # 每训练完一次就重置一次网络状态，网络状态与网络权重不同\n",
        "        model.reset_states()\n",
        "    return model\n",
        " \n",
        "# 构建一个LSTM模型并训练，batch_size为1，训练次数为3，LSTM层神经元个数为4       \n",
        "lstm_model=fit_lstm(train_scaled,1,3,4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC5m5s0ZkfF1",
        "outputId": "c8c12ad9-a003-427a-8636-f4b7e1889906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 2s 2ms/step - loss: 0.0541\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0496\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.0492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 模型的泛化"
      ],
      "metadata": {
        "id": "o5sHNWltlehL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 将一条数据的输入和输出列分开，并且将输入进行变换，传入到预测函数中进行单步预测\n",
        "def forecast_lstm(model,batch_size,X):\n",
        "    # 将形状为[1:]的，包含一个元素的一维数组X，转换形状为[1,1,1]的3D张量\n",
        "    print(type(X))\n",
        "    X=X.reshape(1,1,len(X))\n",
        "    X=X.astype(np.float32)\n",
        "    \n",
        "    # 输出形状为1行一列的二维数组yhat\n",
        "    yhat=model.predict(X,batch_size=batch_size)\n",
        "    # 将yhat中的结果返回\n",
        "    return yhat[0,0]\n",
        "\n",
        "# 得到预测值后对其进行逆缩放和逆差分，将其还原到原来的取值范围内\n",
        "# 对预测的数据进行逆差分转换\n",
        "def invert_difference(history,yhat,interval=1):\n",
        "    return yhat+history[-interval]\n",
        " \n",
        "# 将预测值进行逆缩放，使用之前训练好的缩放器，x为一维数组，y为实数\n",
        "def invert_scale(scaler,X,y):\n",
        "    # 将X,y转换为一个list列表\n",
        "    new_row=[x for x in X]+[y]\n",
        "    # 将列表转换为数组\n",
        "    array=np.array(new_row)\n",
        "    # 将数组重构成一个形状为[1,2]的二维数组->[[10,12]]\n",
        "    array=array.reshape(1,len(array))\n",
        "    # 逆缩放输入的形状为[1,2]，输出形状也是如此\n",
        "    invert=scaler.inverse_transform(array)\n",
        "    # 只需要返回y值即可\n",
        "    return invert[0,-1]\n",
        "\n",
        "# 遍历全部测试集数据，对每行数据执行以上操作，并将最终的预测值保存下来\n",
        "predictions=list()\n",
        "for i in range(len(test_scaled)):\n",
        "    # 将测试集拆分为X和y\n",
        "    # X,y=test[i,0:-1],test[i,-1]\n",
        "    X,y=test_scaled[i,0:-1],test[i,-1]\n",
        "    print('X',X)\n",
        "    # 将训练好的模型、测试数据传入预测函数中\n",
        "    yhat=forecast_lstm(lstm_model,1,X)\n",
        "    # 将预测值进行逆缩放\n",
        "    yhat=invert_scale(scaler,X,yhat)\n",
        "    # 对预测的y值进行逆差分\n",
        "    print('yhat前',yhat)\n",
        "    yhat=invert_difference(raw_value,yhat,len(test_scaled)+1-i)\n",
        "    print('yhat后来',yhat)\n",
        "    print('len(test_scaled)+1-i',len(test_scaled)+1-i)\n",
        "    \n",
        "    # 存储正在预测的y值\n",
        "    predictions.append(yhat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0owZtUk2lTi7",
        "outputId": "6ac4f1c5-5351-48c1-91d7-d3b308062391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X [0.16405374]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 320ms/step\n",
            "yhat前 -5587.688741553574\n",
            "yhat后来 [26554.31125845]\n",
            "len(test_scaled)+1-i 109\n",
            "X [0.14290112]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -5006.839703213423\n",
            "yhat后来 [28337.16029679]\n",
            "len(test_scaled)+1-i 108\n",
            "X [0.18340333]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -4869.281697027384\n",
            "yhat后来 [32439.71830297]\n",
            "len(test_scaled)+1-i 107\n",
            "X [0.06824395]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -3354.0272033922365\n",
            "yhat后来 [30063.97279661]\n",
            "len(test_scaled)+1-i 106\n",
            "X [0.12064909]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -2862.9066810421637\n",
            "yhat后来 [30239.09331896]\n",
            "len(test_scaled)+1-i 105\n",
            "X [0.15383657]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -2813.2901225537053\n",
            "yhat后来 [32236.70987745]\n",
            "len(test_scaled)+1-i 104\n",
            "X [0.06997369]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "yhat前 -1768.3431081771841\n",
            "yhat后来 [29508.65689182]\n",
            "len(test_scaled)+1-i 103\n",
            "X [0.13552775]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat前 -1774.0357034206381\n",
            "yhat后来 [30201.96429658]\n",
            "len(test_scaled)+1-i 102\n",
            "X [0.16162038]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -1999.2662838324895\n",
            "yhat后来 [32455.73371617]\n",
            "len(test_scaled)+1-i 101\n",
            "X [0.0820965]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat前 -1212.6258613020173\n",
            "yhat后来 [30296.3741387]\n",
            "len(test_scaled)+1-i 100\n",
            "X [0.1438686]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "yhat前 -1357.4007567614308\n",
            "yhat后来 [31419.59924324]\n",
            "len(test_scaled)+1-i 99\n",
            "X [0.0698271]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -606.3136411309233\n",
            "yhat后来 [28387.68635887]\n",
            "len(test_scaled)+1-i 98\n",
            "X [0.16503588]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -1150.72193763405\n",
            "yhat后来 [30555.27806237]\n",
            "len(test_scaled)+1-i 97\n",
            "X [0.11471228]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat前 -920.7044945433726\n",
            "yhat后来 [30064.29550546]\n",
            "len(test_scaled)+1-i 96\n",
            "X [0.13070501]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -920.9311818182458\n",
            "yhat后来 [30434.06881818]\n",
            "len(test_scaled)+1-i 95\n",
            "X [0.11241086]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -706.0763727724542\n",
            "yhat后来 [29770.92362723]\n",
            "len(test_scaled)+1-i 94\n",
            "X [0.13621672]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -814.2458477467288\n",
            "yhat后来 [30408.75415225]\n",
            "len(test_scaled)+1-i 93\n",
            "X [0.08099709]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat前 -269.46143334358834\n",
            "yhat后来 [27932.53856666]\n",
            "len(test_scaled)+1-i 92\n",
            "X [0.15292772]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -701.3891305103888\n",
            "yhat后来 [29386.61086949]\n",
            "len(test_scaled)+1-i 91\n",
            "X [0.15753058]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -1013.5781694054593\n",
            "yhat后来 [31274.42183059]\n",
            "len(test_scaled)+1-i 90\n",
            "X [0.12126476]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "yhat前 -798.397052668034\n",
            "yhat后来 [31215.60294733]\n",
            "len(test_scaled)+1-i 89\n",
            "X [0.10946444]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -522.6640036329618\n",
            "yhat后来 [30412.33599637]\n",
            "len(test_scaled)+1-i 88\n",
            "X [0.14854475]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -770.1841440275301\n",
            "yhat后来 [31751.81585597]\n",
            "len(test_scaled)+1-i 87\n",
            "X [0.07403417]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -115.1453416422\n",
            "yhat后来 [28910.85465836]\n",
            "len(test_scaled)+1-i 86\n",
            "X [0.09418999]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 76.84149908274506\n",
            "yhat后来 [26981.84149908]\n",
            "len(test_scaled)+1-i 85\n",
            "X [0.14731341]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -388.6450635790815\n",
            "yhat后来 [28019.35493642]\n",
            "len(test_scaled)+1-i 84\n",
            "X [0.10285333]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "yhat前 -196.47423004358913\n",
            "yhat后来 [26681.52576996]\n",
            "len(test_scaled)+1-i 83\n",
            "X [0.15015722]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "yhat前 -578.1241127923122\n",
            "yhat后来 [27996.87588721]\n",
            "len(test_scaled)+1-i 82\n",
            "X [0.13372472]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -638.4717215821137\n",
            "yhat后来 [28512.52827842]\n",
            "len(test_scaled)+1-i 81\n",
            "X [0.09663801]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -264.3543621823182\n",
            "yhat后来 [26932.64563782]\n",
            "len(test_scaled)+1-i 80\n",
            "X [0.15033312]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -609.339865423738\n",
            "yhat后来 [28296.66013458]\n",
            "len(test_scaled)+1-i 79\n",
            "X [0.14722546]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -793.3519901335229\n",
            "yhat后来 [29609.64800987]\n",
            "len(test_scaled)+1-i 78\n",
            "X [0.12610216]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "yhat前 -670.4376769438376\n",
            "yhat后来 [29788.56232306]\n",
            "len(test_scaled)+1-i 77\n",
            "X [0.13715488]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -706.3315230235447\n",
            "yhat后来 [30562.66847698]\n",
            "len(test_scaled)+1-i 76\n",
            "X [0.08633289]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -179.53164345025922\n",
            "yhat后来 [28432.46835655]\n",
            "len(test_scaled)+1-i 75\n",
            "X [0.12103022]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -228.1789359450331\n",
            "yhat后来 [28093.82106405]\n",
            "len(test_scaled)+1-i 74\n",
            "X [0.13142329]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -380.11226992308997\n",
            "yhat后来 [28360.88773008]\n",
            "len(test_scaled)+1-i 73\n",
            "X [0.12375675]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -390.3416602686038\n",
            "yhat后来 [28246.65833973]\n",
            "len(test_scaled)+1-i 72\n",
            "X [0.13183374]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "yhat前 -480.76040343195103\n",
            "yhat后来 [28603.23959657]\n",
            "len(test_scaled)+1-i 71\n",
            "X [0.12813973]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat前 -496.44858600199126\n",
            "yhat后来 [28782.551414]\n",
            "len(test_scaled)+1-i 70\n",
            "X [0.12041455]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -420.4493898972859\n",
            "yhat后来 [28526.5506101]\n",
            "len(test_scaled)+1-i 69\n",
            "X [0.12536922]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -426.0067860037079\n",
            "yhat后来 [28526.993214]\n",
            "len(test_scaled)+1-i 68\n",
            "X [0.14155251]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "yhat前 -604.0986116603008\n",
            "yhat后来 [29458.90138834]\n",
            "len(test_scaled)+1-i 67\n",
            "X [0.08930862]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "yhat前 -149.72582467645313\n",
            "yhat后来 [27459.27417532]\n",
            "len(test_scaled)+1-i 66\n",
            "X [0.12962026]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -301.774027094244\n",
            "yhat后来 [27603.22597291]\n",
            "len(test_scaled)+1-i 65\n",
            "X [0.08498428]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat前 77.94240634143446\n",
            "yhat后来 [25233.94240634]\n",
            "len(test_scaled)+1-i 64\n",
            "X [0.11818642]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -47.215399295090684\n",
            "yhat后来 [24624.7846007]\n",
            "len(test_scaled)+1-i 63\n",
            "X [0.1520482]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat前 -496.36218053847455\n",
            "yhat后来 [26001.63781946]\n",
            "len(test_scaled)+1-i 62\n",
            "X [0.13999868]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -642.6151176914562\n",
            "yhat后来 [26859.38488231]\n",
            "len(test_scaled)+1-i 61\n",
            "X [0.12774394]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -592.0475908368817\n",
            "yhat后来 [27077.95240916]\n",
            "len(test_scaled)+1-i 60\n",
            "X [0.15289841]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -825.8628081828346\n",
            "yhat后来 [28728.13719182]\n",
            "len(test_scaled)+1-i 59\n",
            "X [0.09268014]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -321.41957989334963\n",
            "yhat后来 [27008.58042011]\n",
            "len(test_scaled)+1-i 58\n",
            "X [0.1606529]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -733.6275172159066\n",
            "yhat后来 [29009.37248278]\n",
            "len(test_scaled)+1-i 57\n",
            "X [0.14470415]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -827.6264961734404\n",
            "yhat后来 [30240.37350383]\n",
            "len(test_scaled)+1-i 56\n",
            "X [0.05239781]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 125.77545440942143\n",
            "yhat后来 [26221.77545441]\n",
            "len(test_scaled)+1-i 55\n",
            "X [0.14165512]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -253.80679642408992\n",
            "yhat后来 [26959.19320358]\n",
            "len(test_scaled)+1-i 54\n",
            "X [0.15124197]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -608.2054125145069\n",
            "yhat后来 [28375.79458749]\n",
            "len(test_scaled)+1-i 53\n",
            "X [0.1030439]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -301.8594160228958\n",
            "yhat后来 [27165.14058398]\n",
            "len(test_scaled)+1-i 52\n",
            "X [0.10367422]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat前 -113.19766084104681\n",
            "yhat后来 [25879.80233916]\n",
            "len(test_scaled)+1-i 51\n",
            "X [0.10574111]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat前 -26.972123995422372\n",
            "yhat后来 [24633.027876]\n",
            "len(test_scaled)+1-i 50\n",
            "X [0.13151125]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat前 -256.96821985393666\n",
            "yhat后来 [24828.03178015]\n",
            "len(test_scaled)+1-i 49\n",
            "X [0.14655116]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "yhat前 -562.7297087982288\n",
            "yhat后来 [25973.2702912]\n",
            "len(test_scaled)+1-i 48\n",
            "X [0.13904586]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -667.107508726417\n",
            "yhat后来 [26807.89249127]\n",
            "len(test_scaled)+1-i 47\n",
            "X [0.09744424]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -276.1126209646454\n",
            "yhat后来 [25299.88737904]\n",
            "len(test_scaled)+1-i 46\n",
            "X [0.1529717]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "yhat前 -629.586190328001\n",
            "yhat后来 [26835.41380967]\n",
            "len(test_scaled)+1-i 45\n",
            "X [0.15083152]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -831.8024213984598\n",
            "yhat后来 [28376.1975786]\n",
            "len(test_scaled)+1-i 44\n",
            "X [0.05991776]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 35.882259771228775\n",
            "yhat后来 [24784.88225977]\n",
            "len(test_scaled)+1-i 43\n",
            "X [0.12882869]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -173.6601380705824\n",
            "yhat后来 [24817.33986193]\n",
            "len(test_scaled)+1-i 42\n",
            "X [0.11497614]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -170.46008631586935\n",
            "yhat后来 [24117.53991368]\n",
            "len(test_scaled)+1-i 41\n",
            "X [0.17144176]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat前 -769.5477932021012\n",
            "yhat后来 [26667.4522068]\n",
            "len(test_scaled)+1-i 40\n",
            "X [0.11393537]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -525.2612502127877\n",
            "yhat后来 [26137.73874979]\n",
            "len(test_scaled)+1-i 39\n",
            "X [0.14055571]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat前 -646.3427510410537\n",
            "yhat后来 [27058.65724896]\n",
            "len(test_scaled)+1-i 38\n",
            "X [0.07385826]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -4.438595645128738\n",
            "yhat后来 [24192.56140435]\n",
            "len(test_scaled)+1-i 37\n",
            "X [0.15729604]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -506.50821502506636\n",
            "yhat后来 [25874.49178497]\n",
            "len(test_scaled)+1-i 36\n",
            "X [0.1080572]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -300.1557035893192\n",
            "yhat后来 [24905.84429641]\n",
            "len(test_scaled)+1-i 35\n",
            "X [0.13766793]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -481.3276298865666\n",
            "yhat后来 [25569.67237011]\n",
            "len(test_scaled)+1-i 34\n",
            "X [0.09139017]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -98.63274929672384\n",
            "yhat后来 [23640.3672507]\n",
            "len(test_scaled)+1-i 33\n",
            "X [-0.18504511]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 3261.313840456308\n",
            "yhat后来 [5830.31384046]\n",
            "len(test_scaled)+1-i 32\n",
            "X [0.41932174]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "yhat前 -1261.400220654904\n",
            "yhat后来 [21366.59977935]\n",
            "len(test_scaled)+1-i 31\n",
            "X [0.15486268]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -1338.5643657147875\n",
            "yhat后来 [23307.43563429]\n",
            "len(test_scaled)+1-i 30\n",
            "X [0.11395003]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -848.658602528273\n",
            "yhat后来 [23024.34139747]\n",
            "len(test_scaled)+1-i 29\n",
            "X [0.15025983]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -936.3540487885465\n",
            "yhat后来 [24640.64595121]\n",
            "len(test_scaled)+1-i 28\n",
            "X [0.08974838]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -345.0570651069274\n",
            "yhat后来 [22807.94293489]\n",
            "len(test_scaled)+1-i 27\n",
            "X [0.13049979]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -415.94512391090296\n",
            "yhat后来 [23093.05487609]\n",
            "len(test_scaled)+1-i 26\n",
            "X [0.14565697]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -634.4279458895315\n",
            "yhat后来 [24264.57205411]\n",
            "len(test_scaled)+1-i 25\n",
            "X [0.07104378]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 38.47442367673014\n",
            "yhat后来 [21237.47442368]\n",
            "len(test_scaled)+1-i 24\n",
            "X [0.16106335]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat前 -515.155877120792\n",
            "yhat后来 [23124.84412288]\n",
            "len(test_scaled)+1-i 23\n",
            "X [0.08888351]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "yhat前 -94.31145958602333\n",
            "yhat后来 [21062.68854041]\n",
            "len(test_scaled)+1-i 22\n",
            "X [0.1368617]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -342.8704986125221\n",
            "yhat后来 [21604.12950139]\n",
            "len(test_scaled)+1-i 21\n",
            "X [0.1388553]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -527.3715765923253\n",
            "yhat后来 [22345.62842341]\n",
            "len(test_scaled)+1-i 20\n",
            "X [0.14328225]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -683.9006646946062\n",
            "yhat后来 [23417.09933531]\n",
            "len(test_scaled)+1-i 19\n",
            "X [0.07724444]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -63.27766669541503\n",
            "yhat后来 [20760.7223333]\n",
            "len(test_scaled)+1-i 18\n",
            "X [0.14509994]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -411.04542586207293\n",
            "yhat后来 [21764.95457414]\n",
            "len(test_scaled)+1-i 17\n",
            "X [0.13520526]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -531.679651349782\n",
            "yhat后来 [22321.32034865]\n",
            "len(test_scaled)+1-i 16\n",
            "X [0.11770268]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "yhat前 -410.6977709382763\n",
            "yhat后来 [21925.30222906]\n",
            "len(test_scaled)+1-i 15\n",
            "X [0.12278927]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -388.7477336004367\n",
            "yhat后来 [21777.2522664]\n",
            "len(test_scaled)+1-i 14\n",
            "X [0.18162962]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat前 -1005.0423261448731\n",
            "yhat后来 [25004.95767386]\n",
            "len(test_scaled)+1-i 13\n",
            "X [0.09782537]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -489.5513969436278\n",
            "yhat后来 [23647.44860306]\n",
            "len(test_scaled)+1-i 12\n",
            "X [0.09659403]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat前 -140.8809548169365\n",
            "yhat后来 [22039.11904518]\n",
            "len(test_scaled)+1-i 11\n",
            "X [0.10050793]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 19.811860091985213\n",
            "yhat后来 [20509.81186009]\n",
            "len(test_scaled)+1-i 10\n",
            "X [0.14649252]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat前 -384.167227499186\n",
            "yhat后来 [21552.8327725]\n",
            "len(test_scaled)+1-i 9\n",
            "X [0.10100633]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat前 -148.06175710260774\n",
            "yhat后来 [20132.9382429]\n",
            "len(test_scaled)+1-i 8\n",
            "X [0.05598921]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 494.84876780957075\n",
            "yhat后来 [16048.84876781]\n",
            "len(test_scaled)+1-i 7\n",
            "X [0.19061545]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat前 -570.2469841241827\n",
            "yhat后来 [19440.75301588]\n",
            "len(test_scaled)+1-i 6\n",
            "X [0.13800509]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -677.1305424943556\n",
            "yhat后来 [20201.86945751]\n",
            "len(test_scaled)+1-i 5\n",
            "X [0.1147416]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -471.00065219402217\n",
            "yhat后来 [19688.99934781]\n",
            "len(test_scaled)+1-i 4\n",
            "X [0.12295052]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat前 -430.0424294173708\n",
            "yhat后来 [19570.95757058]\n",
            "len(test_scaled)+1-i 3\n",
            "X [0.14291578]\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat前 -622.0272370725861\n",
            "yhat后来 [20581.97276293]\n",
            "len(test_scaled)+1-i 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIxKwrDCua0-",
        "outputId": "c9fdb611-a1d6-424b-d3c9-4adfd9322bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([26554.31125845]),\n",
              " array([28337.16029679]),\n",
              " array([32439.71830297]),\n",
              " array([30063.97279661]),\n",
              " array([30239.09331896]),\n",
              " array([32236.70987745]),\n",
              " array([29508.65689182]),\n",
              " array([30201.96429658]),\n",
              " array([32455.73371617]),\n",
              " array([30296.3741387]),\n",
              " array([31419.59924324]),\n",
              " array([28387.68635887]),\n",
              " array([30555.27806237]),\n",
              " array([30064.29550546]),\n",
              " array([30434.06881818]),\n",
              " array([29770.92362723]),\n",
              " array([30408.75415225]),\n",
              " array([27932.53856666]),\n",
              " array([29386.61086949]),\n",
              " array([31274.42183059]),\n",
              " array([31215.60294733]),\n",
              " array([30412.33599637]),\n",
              " array([31751.81585597]),\n",
              " array([28910.85465836]),\n",
              " array([26981.84149908]),\n",
              " array([28019.35493642]),\n",
              " array([26681.52576996]),\n",
              " array([27996.87588721]),\n",
              " array([28512.52827842]),\n",
              " array([26932.64563782]),\n",
              " array([28296.66013458]),\n",
              " array([29609.64800987]),\n",
              " array([29788.56232306]),\n",
              " array([30562.66847698]),\n",
              " array([28432.46835655]),\n",
              " array([28093.82106405]),\n",
              " array([28360.88773008]),\n",
              " array([28246.65833973]),\n",
              " array([28603.23959657]),\n",
              " array([28782.551414]),\n",
              " array([28526.5506101]),\n",
              " array([28526.993214]),\n",
              " array([29458.90138834]),\n",
              " array([27459.27417532]),\n",
              " array([27603.22597291]),\n",
              " array([25233.94240634]),\n",
              " array([24624.7846007]),\n",
              " array([26001.63781946]),\n",
              " array([26859.38488231]),\n",
              " array([27077.95240916]),\n",
              " array([28728.13719182]),\n",
              " array([27008.58042011]),\n",
              " array([29009.37248278]),\n",
              " array([30240.37350383]),\n",
              " array([26221.77545441]),\n",
              " array([26959.19320358]),\n",
              " array([28375.79458749]),\n",
              " array([27165.14058398]),\n",
              " array([25879.80233916]),\n",
              " array([24633.027876]),\n",
              " array([24828.03178015]),\n",
              " array([25973.2702912]),\n",
              " array([26807.89249127]),\n",
              " array([25299.88737904]),\n",
              " array([26835.41380967]),\n",
              " array([28376.1975786]),\n",
              " array([24784.88225977]),\n",
              " array([24817.33986193]),\n",
              " array([24117.53991368]),\n",
              " array([26667.4522068]),\n",
              " array([26137.73874979]),\n",
              " array([27058.65724896]),\n",
              " array([24192.56140435]),\n",
              " array([25874.49178497]),\n",
              " array([24905.84429641]),\n",
              " array([25569.67237011]),\n",
              " array([23640.3672507]),\n",
              " array([5830.31384046]),\n",
              " array([21366.59977935]),\n",
              " array([23307.43563429]),\n",
              " array([23024.34139747]),\n",
              " array([24640.64595121]),\n",
              " array([22807.94293489]),\n",
              " array([23093.05487609]),\n",
              " array([24264.57205411]),\n",
              " array([21237.47442368]),\n",
              " array([23124.84412288]),\n",
              " array([21062.68854041]),\n",
              " array([21604.12950139]),\n",
              " array([22345.62842341]),\n",
              " array([23417.09933531]),\n",
              " array([20760.7223333]),\n",
              " array([21764.95457414]),\n",
              " array([22321.32034865]),\n",
              " array([21925.30222906]),\n",
              " array([21777.2522664]),\n",
              " array([25004.95767386]),\n",
              " array([23647.44860306]),\n",
              " array([22039.11904518]),\n",
              " array([20509.81186009]),\n",
              " array([21552.8327725]),\n",
              " array([20132.9382429]),\n",
              " array([16048.84876781]),\n",
              " array([19440.75301588]),\n",
              " array([20201.86945751]),\n",
              " array([19688.99934781]),\n",
              " array([19570.95757058]),\n",
              " array([20581.97276293])]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_value[-testNum:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCbLbOy01QHR",
        "outputId": "a2347eba-6b63-4550-c51c-013e93f0d0e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[33344],\n",
              "       [37309],\n",
              "       [33418],\n",
              "       [33102],\n",
              "       [35050],\n",
              "       [31277],\n",
              "       [31976],\n",
              "       [34455],\n",
              "       [31509],\n",
              "       [32777],\n",
              "       [28994],\n",
              "       [31706],\n",
              "       [30985],\n",
              "       [31355],\n",
              "       [30477],\n",
              "       [31223],\n",
              "       [28202],\n",
              "       [30088],\n",
              "       [32288],\n",
              "       [32014],\n",
              "       [30935],\n",
              "       [32522],\n",
              "       [29026],\n",
              "       [26905],\n",
              "       [28408],\n",
              "       [26878],\n",
              "       [28575],\n",
              "       [29151],\n",
              "       [27197],\n",
              "       [28906],\n",
              "       [30403],\n",
              "       [30459],\n",
              "       [31269],\n",
              "       [28612],\n",
              "       [28322],\n",
              "       [28741],\n",
              "       [28637],\n",
              "       [29084],\n",
              "       [29279],\n",
              "       [28947],\n",
              "       [28953],\n",
              "       [30063],\n",
              "       [27609],\n",
              "       [27905],\n",
              "       [25156],\n",
              "       [24672],\n",
              "       [26498],\n",
              "       [27502],\n",
              "       [27670],\n",
              "       [29554],\n",
              "       [27330],\n",
              "       [29743],\n",
              "       [31068],\n",
              "       [26096],\n",
              "       [27213],\n",
              "       [28984],\n",
              "       [27467],\n",
              "       [25993],\n",
              "       [24660],\n",
              "       [25085],\n",
              "       [26536],\n",
              "       [27475],\n",
              "       [25576],\n",
              "       [27465],\n",
              "       [29208],\n",
              "       [24749],\n",
              "       [24991],\n",
              "       [24288],\n",
              "       [27437],\n",
              "       [26663],\n",
              "       [27705],\n",
              "       [24197],\n",
              "       [26381],\n",
              "       [25206],\n",
              "       [26051],\n",
              "       [23739],\n",
              "       [ 2569],\n",
              "       [22628],\n",
              "       [24646],\n",
              "       [23873],\n",
              "       [25577],\n",
              "       [23153],\n",
              "       [23509],\n",
              "       [24899],\n",
              "       [21199],\n",
              "       [23640],\n",
              "       [21157],\n",
              "       [21947],\n",
              "       [22873],\n",
              "       [24101],\n",
              "       [20824],\n",
              "       [22176],\n",
              "       [22853],\n",
              "       [22336],\n",
              "       [22166],\n",
              "       [26010],\n",
              "       [24137],\n",
              "       [22180],\n",
              "       [20490],\n",
              "       [21937],\n",
              "       [20281],\n",
              "       [15554],\n",
              "       [20011],\n",
              "       [20879],\n",
              "       [20160],\n",
              "       [20001],\n",
              "       [21204],\n",
              "       [20380]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 预测结果的可视化"
      ],
      "metadata": {
        "id": "Xuf360_4mXPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 将测试集的y值和预测值绘制在同一张图表中\n",
        "# 计算方差\n",
        "rmse=mean_squared_error(raw_value[-testNum:],predictions)\n",
        "print(\"Test RMSE:\",rmse)\n",
        "# 计算相对误差\n",
        "erro=(predictions-raw_value[-testNum:])/raw_value[-testNum:]\n",
        "# print(\"Erro:\",erro)\n",
        "Mean=np.mean(erro)\n",
        "print(\"Mean:\",Mean)\n",
        "plt.plot(raw_value[-testNum:])\n",
        "plt.plot(predictions)\n",
        "plt.legend(['true','pred'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "CYLdSfP0mYb_",
        "outputId": "87b8cd24-f5fc-4237-9065-07d595af2d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 11607635.888778232\n",
            "Mean: 0.051215546476497335\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 推理"
      ],
      "metadata": {
        "id": "1WiT5LjQ21g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 推理一个\n",
        "scaler=MinMaxScaler(feature_range=(-1,1))\n",
        "scaler=scaler.fit(train)\n",
        "test_scaled=scaler.transform([[1203,-824]])\n",
        "print(test_scaled)# 归一化\n",
        "# 将训练好的模型、测试数据传入预测函数中\n",
        "yhat=forecast_lstm(lstm_model,1,np.array([test_scaled[0][1]]))\n",
        "# 将预测值进行逆缩放\n",
        "yhat=invert_scale(scaler,np.array([test_scaled[0][1]]),yhat)\n",
        "# 对预测的y值进行逆差分\n",
        "yhat=yhat+20380\n",
        "print('yhat后',yhat)\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "sg4jiIu5PKhr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b9a62a2f-b112-40c6-82a5-d7a74224715e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# 推理一个\\nscaler=MinMaxScaler(feature_range=(-1,1))\\nscaler=scaler.fit(train)\\ntest_scaled=scaler.transform([[1203,-824]])\\nprint(test_scaled)# 归一化\\n# 将训练好的模型、测试数据传入预测函数中\\nyhat=forecast_lstm(lstm_model,1,np.array([test_scaled[0][1]]))\\n# 将预测值进行逆缩放\\nyhat=invert_scale(scaler,np.array([test_scaled[0][1]]),yhat)\\n# 对预测的y值进行逆差分\\nyhat=yhat+20380\\nprint('yhat后',yhat)\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 60天 到2023 3月1\n",
        "chafenbiao=[[1203,-824]]# 第一组差分\n",
        "results=[20380]# 第一个结果\n",
        "# 归一化\n",
        "scaler=MinMaxScaler(feature_range=(-1,1))\n",
        "scaler=scaler.fit(train)\n",
        "\n",
        "for i in range(59):\n",
        "    print('i=',i)\n",
        "    # 测试数据归一化\n",
        "    test_scaled=scaler.transform([chafenbiao[i]])\n",
        "    print('test_scaled',test_scaled)\n",
        "    X=test_scaled[0][1]\n",
        "    print('X',X)\n",
        "    # 预测\n",
        "    yhat=forecast_lstm(lstm_model,1,np.array([X]))\n",
        "    # 逆缩放\n",
        "    yhatnsf=invert_scale(scaler,np.array([X]),yhat)\n",
        "    yhatnsf=int(yhatnsf)\n",
        "    # 逆差分\n",
        "    yhatncf=yhatnsf+results[i]\n",
        "    print('yhat逆缩放+上一个结果',yhatnsf, results[i])\n",
        "    print('预测结果即为yhat逆差分', yhatncf)\n",
        "    # 存储结果(更新差分表及结果值)\n",
        "    results.append(yhatncf)\n",
        "    print('结果列表',results)\n",
        "    cur_chafen=yhatncf-results[i]\n",
        "    chafenbiao.append([chafenbiao[i][1],cur_chafen])\n",
        "    print('差分表',chafenbiao)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H0GnnDAshDA",
        "outputId": "aa71fede-0b5a-4491-b96e-5560ed9ce8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i= 0\n",
            "test_scaled [[0.14291578 0.11320243]]\n",
            "X 0.11320243042576426\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "yhat逆缩放+上一个结果 -420 20380\n",
            "预测结果即为yhat逆差分 19960\n",
            "结果列表 [20380, 19960]\n",
            "差分表 [[1203, -824], [-824, -420]]\n",
            "i= 1\n",
            "test_scaled [[0.11320243 0.11912458]]\n",
            "X 0.11912457764389424\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "yhat逆缩放+上一个结果 -355 19960\n",
            "预测结果即为yhat逆差分 19605\n",
            "结果列表 [20380, 19960, 19605]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355]]\n",
            "i= 2\n",
            "test_scaled [[0.11912458 0.1200774 ]]\n",
            "X 0.12007739835968248\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat逆缩放+上一个结果 -329 19605\n",
            "预测结果即为yhat逆差分 19276\n",
            "结果列表 [20380, 19960, 19605, 19276]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329]]\n",
            "i= 3\n",
            "test_scaled [[0.1200774  0.12045853]]\n",
            "X 0.12045852664599777\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat逆缩放+上一个结果 -318 19276\n",
            "预测结果即为yhat逆差分 18958\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318]]\n",
            "i= 4\n",
            "test_scaled [[0.12045853 0.12061977]]\n",
            "X 0.12061977322866962\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "yhat逆缩放+上一个结果 -314 18958\n",
            "预测结果即为yhat逆差分 18644\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314]]\n",
            "i= 5\n",
            "test_scaled [[0.12061977 0.12067841]]\n",
            "X 0.12067840834964122\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "yhat逆缩放+上一个结果 -313 18644\n",
            "预测结果即为yhat逆差分 18331\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313]]\n",
            "i= 6\n",
            "test_scaled [[0.12067841 0.12069307]]\n",
            "X 0.1206930671298841\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "yhat逆缩放+上一个结果 -314 18331\n",
            "预测结果即为yhat逆差分 18017\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314]]\n",
            "i= 7\n",
            "test_scaled [[0.12069307 0.12067841]]\n",
            "X 0.12067840834964122\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat逆缩放+上一个结果 -314 18017\n",
            "预测结果即为yhat逆差分 17703\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314]]\n",
            "i= 8\n",
            "test_scaled [[0.12067841 0.12067841]]\n",
            "X 0.12067840834964122\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat逆缩放+上一个结果 -315 17703\n",
            "预测结果即为yhat逆差分 17388\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315]]\n",
            "i= 9\n",
            "test_scaled [[0.12067841 0.12066375]]\n",
            "X 0.12066374956939832\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat逆缩放+上一个结果 -315 17388\n",
            "预测结果即为yhat逆差分 17073\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315]]\n",
            "i= 10\n",
            "test_scaled [[0.12066375 0.12066375]]\n",
            "X 0.12066374956939832\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat逆缩放+上一个结果 -316 17073\n",
            "预测结果即为yhat逆差分 16757\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316]]\n",
            "i= 11\n",
            "test_scaled [[0.12066375 0.12064909]]\n",
            "X 0.12064909078915542\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat逆缩放+上一个结果 -317 16757\n",
            "预测结果即为yhat逆差分 16440\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317]]\n",
            "i= 12\n",
            "test_scaled [[0.12064909 0.12063443]]\n",
            "X 0.12063443200891252\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat逆缩放+上一个结果 -317 16440\n",
            "预测结果即为yhat逆差分 16123\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317]]\n",
            "i= 13\n",
            "test_scaled [[0.12063443 0.12063443]]\n",
            "X 0.12063443200891252\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat逆缩放+上一个结果 -318 16123\n",
            "预测结果即为yhat逆差分 15805\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318]]\n",
            "i= 14\n",
            "test_scaled [[0.12063443 0.12061977]]\n",
            "X 0.12061977322866962\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat逆缩放+上一个结果 -318 15805\n",
            "预测结果即为yhat逆差分 15487\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318]]\n",
            "i= 15\n",
            "test_scaled [[0.12061977 0.12061977]]\n",
            "X 0.12061977322866962\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat逆缩放+上一个结果 -318 15487\n",
            "预测结果即为yhat逆差分 15169\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318]]\n",
            "i= 16\n",
            "test_scaled [[0.12061977 0.12061977]]\n",
            "X 0.12061977322866962\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat逆缩放+上一个结果 -319 15169\n",
            "预测结果即为yhat逆差分 14850\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319]]\n",
            "i= 17\n",
            "test_scaled [[0.12061977 0.12060511]]\n",
            "X 0.12060511444842673\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat逆缩放+上一个结果 -319 14850\n",
            "预测结果即为yhat逆差分 14531\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319]]\n",
            "i= 18\n",
            "test_scaled [[0.12060511 0.12060511]]\n",
            "X 0.12060511444842673\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat逆缩放+上一个结果 -319 14531\n",
            "预测结果即为yhat逆差分 14212\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319]]\n",
            "i= 19\n",
            "test_scaled [[0.12060511 0.12060511]]\n",
            "X 0.12060511444842673\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat逆缩放+上一个结果 -319 14212\n",
            "预测结果即为yhat逆差分 13893\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319]]\n",
            "i= 20\n",
            "test_scaled [[0.12060511 0.12060511]]\n",
            "X 0.12060511444842673\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat逆缩放+上一个结果 -320 13893\n",
            "预测结果即为yhat逆差分 13573\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320]]\n",
            "i= 21\n",
            "test_scaled [[0.12060511 0.12059046]]\n",
            "X 0.12059045566818384\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat逆缩放+上一个结果 -320 13573\n",
            "预测结果即为yhat逆差分 13253\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320]]\n",
            "i= 22\n",
            "test_scaled [[0.12059046 0.12059046]]\n",
            "X 0.12059045566818384\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat逆缩放+上一个结果 -320 13253\n",
            "预测结果即为yhat逆差分 12933\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320]]\n",
            "i= 23\n",
            "test_scaled [[0.12059046 0.12059046]]\n",
            "X 0.12059045566818384\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat逆缩放+上一个结果 -320 12933\n",
            "预测结果即为yhat逆差分 12613\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320]]\n",
            "i= 24\n",
            "test_scaled [[0.12059046 0.12059046]]\n",
            "X 0.12059045566818384\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat逆缩放+上一个结果 -320 12613\n",
            "预测结果即为yhat逆差分 12293\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320]]\n",
            "i= 25\n",
            "test_scaled [[0.12059046 0.12059046]]\n",
            "X 0.12059045566818384\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat逆缩放+上一个结果 -320 12293\n",
            "预测结果即为yhat逆差分 11973\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320]]\n",
            "i= 26\n",
            "test_scaled [[0.12059046 0.12059046]]\n",
            "X 0.12059045566818384\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "yhat逆缩放+上一个结果 -320 11973\n",
            "预测结果即为yhat逆差分 11653\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320]]\n",
            "i= 27\n",
            "test_scaled [[0.12059046 0.12059046]]\n",
            "X 0.12059045566818384\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat逆缩放+上一个结果 -320 11653\n",
            "预测结果即为yhat逆差分 11333\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320]]\n",
            "i= 28\n",
            "test_scaled [[0.12059046 0.12059046]]\n",
            "X 0.12059045566818384\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "yhat逆缩放+上一个结果 -321 11333\n",
            "预测结果即为yhat逆差分 11012\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321]]\n",
            "i= 29\n",
            "test_scaled [[0.12059046 0.1205758 ]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "yhat逆缩放+上一个结果 -320 11012\n",
            "预测结果即为yhat逆差分 10692\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320]]\n",
            "i= 30\n",
            "test_scaled [[0.1205758  0.12059046]]\n",
            "X 0.12059045566818384\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "yhat逆缩放+上一个结果 -321 10692\n",
            "预测结果即为yhat逆差分 10371\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321]]\n",
            "i= 31\n",
            "test_scaled [[0.12059046 0.1205758 ]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "yhat逆缩放+上一个结果 -321 10371\n",
            "预测结果即为yhat逆差分 10050\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321]]\n",
            "i= 32\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "yhat逆缩放+上一个结果 -320 10050\n",
            "预测结果即为yhat逆差分 9730\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320]]\n",
            "i= 33\n",
            "test_scaled [[0.1205758  0.12059046]]\n",
            "X 0.12059045566818384\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "yhat逆缩放+上一个结果 -321 9730\n",
            "预测结果即为yhat逆差分 9409\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321]]\n",
            "i= 34\n",
            "test_scaled [[0.12059046 0.1205758 ]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "yhat逆缩放+上一个结果 -321 9409\n",
            "预测结果即为yhat逆差分 9088\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321]]\n",
            "i= 35\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "yhat逆缩放+上一个结果 -321 9088\n",
            "预测结果即为yhat逆差分 8767\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321]]\n",
            "i= 36\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "yhat逆缩放+上一个结果 -321 8767\n",
            "预测结果即为yhat逆差分 8446\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 37\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "yhat逆缩放+上一个结果 -321 8446\n",
            "预测结果即为yhat逆差分 8125\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 38\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "yhat逆缩放+上一个结果 -321 8125\n",
            "预测结果即为yhat逆差分 7804\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 39\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "yhat逆缩放+上一个结果 -321 7804\n",
            "预测结果即为yhat逆差分 7483\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 40\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "yhat逆缩放+上一个结果 -321 7483\n",
            "预测结果即为yhat逆差分 7162\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 41\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "yhat逆缩放+上一个结果 -321 7162\n",
            "预测结果即为yhat逆差分 6841\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 42\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "yhat逆缩放+上一个结果 -321 6841\n",
            "预测结果即为yhat逆差分 6520\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 43\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "yhat逆缩放+上一个结果 -321 6520\n",
            "预测结果即为yhat逆差分 6199\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 44\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "yhat逆缩放+上一个结果 -321 6199\n",
            "预测结果即为yhat逆差分 5878\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 45\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "yhat逆缩放+上一个结果 -321 5878\n",
            "预测结果即为yhat逆差分 5557\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 46\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "yhat逆缩放+上一个结果 -321 5557\n",
            "预测结果即为yhat逆差分 5236\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 47\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "yhat逆缩放+上一个结果 -321 5236\n",
            "预测结果即为yhat逆差分 4915\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236, 4915]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 48\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "yhat逆缩放+上一个结果 -321 4915\n",
            "预测结果即为yhat逆差分 4594\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236, 4915, 4594]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 49\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "yhat逆缩放+上一个结果 -321 4594\n",
            "预测结果即为yhat逆差分 4273\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236, 4915, 4594, 4273]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 50\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "yhat逆缩放+上一个结果 -321 4273\n",
            "预测结果即为yhat逆差分 3952\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236, 4915, 4594, 4273, 3952]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 51\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "yhat逆缩放+上一个结果 -321 3952\n",
            "预测结果即为yhat逆差分 3631\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236, 4915, 4594, 4273, 3952, 3631]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 52\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "yhat逆缩放+上一个结果 -321 3631\n",
            "预测结果即为yhat逆差分 3310\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236, 4915, 4594, 4273, 3952, 3631, 3310]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 53\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "yhat逆缩放+上一个结果 -321 3310\n",
            "预测结果即为yhat逆差分 2989\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236, 4915, 4594, 4273, 3952, 3631, 3310, 2989]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 54\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat逆缩放+上一个结果 -321 2989\n",
            "预测结果即为yhat逆差分 2668\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236, 4915, 4594, 4273, 3952, 3631, 3310, 2989, 2668]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 55\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat逆缩放+上一个结果 -321 2668\n",
            "预测结果即为yhat逆差分 2347\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236, 4915, 4594, 4273, 3952, 3631, 3310, 2989, 2668, 2347]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 56\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "yhat逆缩放+上一个结果 -321 2347\n",
            "预测结果即为yhat逆差分 2026\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236, 4915, 4594, 4273, 3952, 3631, 3310, 2989, 2668, 2347, 2026]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 57\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "yhat逆缩放+上一个结果 -321 2026\n",
            "预测结果即为yhat逆差分 1705\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236, 4915, 4594, 4273, 3952, 3631, 3310, 2989, 2668, 2347, 2026, 1705]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n",
            "i= 58\n",
            "test_scaled [[0.1205758 0.1205758]]\n",
            "X 0.12057579688794094\n",
            "<class 'numpy.ndarray'>\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "yhat逆缩放+上一个结果 -321 1705\n",
            "预测结果即为yhat逆差分 1384\n",
            "结果列表 [20380, 19960, 19605, 19276, 18958, 18644, 18331, 18017, 17703, 17388, 17073, 16757, 16440, 16123, 15805, 15487, 15169, 14850, 14531, 14212, 13893, 13573, 13253, 12933, 12613, 12293, 11973, 11653, 11333, 11012, 10692, 10371, 10050, 9730, 9409, 9088, 8767, 8446, 8125, 7804, 7483, 7162, 6841, 6520, 6199, 5878, 5557, 5236, 4915, 4594, 4273, 3952, 3631, 3310, 2989, 2668, 2347, 2026, 1705, 1384]\n",
            "差分表 [[1203, -824], [-824, -420], [-420, -355], [-355, -329], [-329, -318], [-318, -314], [-314, -313], [-313, -314], [-314, -314], [-314, -315], [-315, -315], [-315, -316], [-316, -317], [-317, -317], [-317, -318], [-318, -318], [-318, -318], [-318, -319], [-319, -319], [-319, -319], [-319, -319], [-319, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -320], [-320, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -320], [-320, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321], [-321, -321]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 预测区间\n",
        "'''\n",
        "a=results[-1]+(results[-1]*Mean)\n",
        "b=results[-1]-(results[-1]*Mean)\n",
        "print('预测区间为：', b,a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nSHKDhxxpsa",
        "outputId": "5bca4d76-bbfd-4f22-c542-0e02644418a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "预测区间为： 1313.1176836765276 1454.8823163234724\n"
          ]
        }
      ]
    }
  ]
}